{"type": "start", "step": "pipeline", "dataset": "lca", "repo_name": "streamlit/streamlit", "repo_base_path": "/Volumes/T9/lca/cloned_repos_test", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:01.127634+00:00"}
{"type": "token_count", "step": "turn_1", "token_count": 2801, "context_size": 16384, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:01.401092+00:00"}
{"type": "prompt", "step": "turn_1", "messages": [{"role": "system", "content": "\nYou are an expert software engineer specialized in bug localization. \nYour task is to identify the files most likely to contain bugs based on bug descriptions. \nYou have access to several tools to help you in this task. \nFrom the files you have seen, you will select 10 files that you believe are most likely to contain the bug.\n"}, {"role": "user", "content": "\n<bug_description>\n`@st.cache_data` cannot handle UUID objects (but `@st.cache` can) ### Checklist\r\n\r\n- [X] I have searched the [existing issues](https://github.com/streamlit/streamlit/issues) for similar issues.\r\n- [X] I added a very descriptive title to this issue.\r\n- [X] I have provided sufficient information below to help reproduce this issue.\r\n\r\n### Summary\r\n\r\nIt looks like the \"new\" `@st.cache_data` decorator chokes on `uuid.UUID` objects, while the deprecated `@st.cache` seems to handle them just fine; see minimal example.\r\n\r\n\r\n### Reproducible Code Example\r\n\r\n```Python\r\nimport streamlit as st\r\nimport uuid\r\n\r\n\r\n@st.cache\r\ndef works(some_id: uuid.UUID) -> None:\r\n    print(\"Works\")\r\n\r\n\r\n@st.cache_data\r\ndef doesnt_work(some_id: uuid.UUID) -> None:\r\n    print(\"Nope\")\r\n\r\n\r\nsome_id = uuid.uuid4()\r\n\r\nworks(some_id)\r\ndoesnt_work(some_id)\r\n```\r\n\r\n\r\n### Steps To Reproduce\r\n\r\n_No response_\r\n\r\n### Expected Behavior\r\n\r\n_No response_\r\n\r\n### Current Behavior\r\n\r\nThe minimal example above produces the following output:\r\n\r\n```\r\n2023-04-06 10:46:30.563 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\r\n2023-04-06 10:46:30.678 \r\n  Warning: to view this Streamlit app on a browser, run it with the following\r\n  command:\r\n\r\n    streamlit run /Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py [ARGUMENTS]\r\n2023-04-06 10:46:30.680 `st.cache` is deprecated. Please use one of Streamlit's new caching commands,\r\n`st.cache_data` or `st.cache_resource`.\r\n\r\nMore information [in our docs](https://docs.streamlit.io/library/advanced-features/caching).\r\n2023-04-06 10:46:30.681 No runtime found, using MemoryCacheStorageManager\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\r\n    reduce_data = obj.__reduce__()\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\r\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\r\nTypeError: cannot pickle 'function' object\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py\", line 20, in <module>\r\n    doesnt_work(some_id)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 194, in wrapper\r\n    return cached_func(*args, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 223, in __call__\r\n    return self._get_or_create_cached_value(args, kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 237, in _get_or_create_cached_value\r\n    value_key = _make_value_key(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 381, in _make_value_key\r\n    raise UnhashableParamError(cache_type, func, arg_name, arg_value, exc)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableParamError: Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n\r\nTo address this, you can tell Streamlit not to hash this argument by adding a\r\nleading underscore to the argument's name in the function signature:\r\n\r\n\\\\```\r\n@st.cache_data\r\ndef doesnt_work(_some_id, ...):\r\n    ...\r\n\\\\```\r\n            \r\nWorks\r\n```\r\n\r\n### Is this a regression?\r\n\r\n- [ ] Yes, this used to work in a previous version.\r\n\r\n### Debug info\r\n\r\n- Streamlit version: 1.20.0\r\n- Python version: 3.10.10\r\n- Operating System: macOS 13.2.1 (22D68)\r\n- Browser: —\r\n- Virtual environment: conda\r\n\r\n\r\n### Additional Information\r\n\r\nThe root of the problems seems to be this:\r\n```\r\nCannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n```\r\nWhich is a little strange because pickling and hashing `UUID` objects does not seem to be a problem in general:\r\n```python\r\n>>> import pickle\r\n>>> import uuid\r\n>>> pickle.dumps(uuid.uuid4())\r\nb'\\\\x80\\\\x04\\\\x950\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x8c\\\\x04uuid\\\\x94\\\\x8c\\\\x04UUID\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94\\\\x8c\\\\x03int\\\\x94\\\\x8a\\\\x10\\\\xa8\\\\x0eL\\\\x84\\\\x14\\\\xd9\\\\xcf\\\\x8d\\\\xae@M\\\\x9e\\\\x11\\\\xb0\\\\x9cvsb.'\r\n>>> hash(uuid.uuid4())\r\n1532964488252874118\r\n```\r\n\r\nA simple workaround for now is to cast `UUID` objects to strings (which are cacheable also with `@st.cache_data`), but of course it would be nicer if that were not necessary :)\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] Yes, I am willing to submit a PR!\n</bug_description>\n\nThe repository name is:\n<repo_name>\nstreamlit/streamlit\n</repo_name>\n\nYou have access to the following tools:\n\n* extract_relevant() -> Retrieve the most relevant info from the bug. Returns a JSON object with explanation, relevant code snippets, error messages and file paths mentioned in the bug. *\n\nYou must use these tools to find 10 files that are most likely to contain the bug. Start by analyzing the issue description and then decide which tool to use first.\nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}], "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:01.401260+00:00"}
{"type": "response", "step": "turn_1", "response": "{\n  \"function_call\": \"extract_relevant\",\n  \"args\": {}\n}", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:05.376061+00:00"}
{"type": "parse", "step": "turn_1", "method": "json", "ok": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:05.381418+00:00"}
{"type": "tool_decision", "step": "turn_1", "tool_name": "extract_relevant", "tool_args": {}, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:05.381526+00:00"}
{"type": "tool_result", "step": "turn_1", "extract_relevant": "{'explanation': \"The @st.cache_data decorator fails to handle uuid.UUID objects while @st.cache works fine. The error occurs during hashing when trying to pickle UUID objects, resulting in UnhashableTypeError. The issue is in the caching mechanism's hash generation for UUID objects.\", 'path': '/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py', 'filename': 'hashing.py', 'identifiers': ['uuid.UUID', 'st.cache_data', 'st.cache'], 'code snippet': '@st.cache_data\\ndef doesnt_work(some_id: uuid.UUID) -> None:\\n    print(\"Nope\")', 'stacktrace': 'Traceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\\n    reduce_data = obj.__reduce__()\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\\nTypeError: cannot pickle \\'function\\' object\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\\n    update_hash(\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\\n    ch.update(hasher, val)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\\n    raise UnhashableTypeError() from ex\\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError', 'error_message': \"Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\"}", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:05.395642+00:00"}
{"type": "token_count", "step": "turn_2", "token_count": 3929, "context_size": 16384, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:05.682984+00:00"}
{"type": "prompt", "step": "turn_2", "messages": [{"role": "system", "content": "\nYou are an expert software engineer specialized in bug localization. \nYour task is to identify the files most likely to contain bugs based on bug descriptions. \nYou have access to several tools to help you in this task. \nFrom the files you have seen, you will select 10 files that you believe are most likely to contain the bug.\n"}, {"role": "user", "content": "\n<bug_description>\n`@st.cache_data` cannot handle UUID objects (but `@st.cache` can) ### Checklist\r\n\r\n- [X] I have searched the [existing issues](https://github.com/streamlit/streamlit/issues) for similar issues.\r\n- [X] I added a very descriptive title to this issue.\r\n- [X] I have provided sufficient information below to help reproduce this issue.\r\n\r\n### Summary\r\n\r\nIt looks like the \"new\" `@st.cache_data` decorator chokes on `uuid.UUID` objects, while the deprecated `@st.cache` seems to handle them just fine; see minimal example.\r\n\r\n\r\n### Reproducible Code Example\r\n\r\n```Python\r\nimport streamlit as st\r\nimport uuid\r\n\r\n\r\n@st.cache\r\ndef works(some_id: uuid.UUID) -> None:\r\n    print(\"Works\")\r\n\r\n\r\n@st.cache_data\r\ndef doesnt_work(some_id: uuid.UUID) -> None:\r\n    print(\"Nope\")\r\n\r\n\r\nsome_id = uuid.uuid4()\r\n\r\nworks(some_id)\r\ndoesnt_work(some_id)\r\n```\r\n\r\n\r\n### Steps To Reproduce\r\n\r\n_No response_\r\n\r\n### Expected Behavior\r\n\r\n_No response_\r\n\r\n### Current Behavior\r\n\r\nThe minimal example above produces the following output:\r\n\r\n```\r\n2023-04-06 10:46:30.563 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\r\n2023-04-06 10:46:30.678 \r\n  Warning: to view this Streamlit app on a browser, run it with the following\r\n  command:\r\n\r\n    streamlit run /Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py [ARGUMENTS]\r\n2023-04-06 10:46:30.680 `st.cache` is deprecated. Please use one of Streamlit's new caching commands,\r\n`st.cache_data` or `st.cache_resource`.\r\n\r\nMore information [in our docs](https://docs.streamlit.io/library/advanced-features/caching).\r\n2023-04-06 10:46:30.681 No runtime found, using MemoryCacheStorageManager\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\r\n    reduce_data = obj.__reduce__()\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\r\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\r\nTypeError: cannot pickle 'function' object\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py\", line 20, in <module>\r\n    doesnt_work(some_id)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 194, in wrapper\r\n    return cached_func(*args, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 223, in __call__\r\n    return self._get_or_create_cached_value(args, kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 237, in _get_or_create_cached_value\r\n    value_key = _make_value_key(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 381, in _make_value_key\r\n    raise UnhashableParamError(cache_type, func, arg_name, arg_value, exc)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableParamError: Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n\r\nTo address this, you can tell Streamlit not to hash this argument by adding a\r\nleading underscore to the argument's name in the function signature:\r\n\r\n\\\\```\r\n@st.cache_data\r\ndef doesnt_work(_some_id, ...):\r\n    ...\r\n\\\\```\r\n            \r\nWorks\r\n```\r\n\r\n### Is this a regression?\r\n\r\n- [ ] Yes, this used to work in a previous version.\r\n\r\n### Debug info\r\n\r\n- Streamlit version: 1.20.0\r\n- Python version: 3.10.10\r\n- Operating System: macOS 13.2.1 (22D68)\r\n- Browser: —\r\n- Virtual environment: conda\r\n\r\n\r\n### Additional Information\r\n\r\nThe root of the problems seems to be this:\r\n```\r\nCannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n```\r\nWhich is a little strange because pickling and hashing `UUID` objects does not seem to be a problem in general:\r\n```python\r\n>>> import pickle\r\n>>> import uuid\r\n>>> pickle.dumps(uuid.uuid4())\r\nb'\\\\x80\\\\x04\\\\x950\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x8c\\\\x04uuid\\\\x94\\\\x8c\\\\x04UUID\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94\\\\x8c\\\\x03int\\\\x94\\\\x8a\\\\x10\\\\xa8\\\\x0eL\\\\x84\\\\x14\\\\xd9\\\\xcf\\\\x8d\\\\xae@M\\\\x9e\\\\x11\\\\xb0\\\\x9cvsb.'\r\n>>> hash(uuid.uuid4())\r\n1532964488252874118\r\n```\r\n\r\nA simple workaround for now is to cast `UUID` objects to strings (which are cacheable also with `@st.cache_data`), but of course it would be nicer if that were not necessary :)\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] Yes, I am willing to submit a PR!\n</bug_description>\n\nThe repository name is:\n<repo_name>\nstreamlit/streamlit\n</repo_name>\n\nYou have access to the following tools:\n\n* extract_relevant() -> Retrieve the most relevant info from the bug. Returns a JSON object with explanation, relevant code snippets, error messages and file paths mentioned in the bug. *\n\nYou must use these tools to find 10 files that are most likely to contain the bug. Start by analyzing the issue description and then decide which tool to use first.\nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}, {"role": "assistant", "content": "extracted info: {'explanation': \"The @st.cache_data decorator fails to handle uuid.UUID objects while @st.cache works fine. The error occurs during hashing when trying to pickle UUID objects, resulting in UnhashableTypeError. The issue is in the caching mechanism's hash generation for UUID objects.\", 'path': '/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py', 'filename': 'hashing.py', 'identifiers': ['uuid.UUID', 'st.cache_data', 'st.cache'], 'code snippet': '@st.cache_data\\ndef doesnt_work(some_id: uuid.UUID) -> None:\\n    print(\"Nope\")', 'stacktrace': 'Traceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\\n    reduce_data = obj.__reduce__()\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\\nTypeError: cannot pickle \\'function\\' object\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\\n    update_hash(\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\\n    ch.update(hasher, val)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\\n    raise UnhashableTypeError() from ex\\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError', 'error_message': \"Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\"}"}, {"role": "user", "content": "\nBased on the tool call results, please select your next action. Recall that you need to provide the 10 files most likely to contain bugs.\n<tool_called>\nextract_relevant\n</tool_called>\n<args>\n{}\n</args>\n\nYou have access to the following tools: \n* get_bm25_top10() -> Retrieve the top-10 best results with BM25 search. *\n* get_bm25_top20() -> Retrieve the top-20 best results with BM25 search.*\n* get_bm25_top30() -> Retrieve the top-30 best results with BM25 search. *\n \nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}], "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:05.683180+00:00"}
{"type": "response", "step": "turn_2", "response": "{\"function_call\": \"get_bm25_top20\", \"args\": {\"query\": \"streamlit cache_data uuid hashing\"}}", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:08.477036+00:00"}
{"type": "parse", "step": "turn_2", "method": "json", "ok": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:08.482226+00:00"}
{"type": "tool_decision", "step": "turn_2", "tool_name": "get_bm25_top20", "tool_args": {"query": "streamlit cache_data uuid hashing"}, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:08.482334+00:00"}
{"type": "bm25_query", "step": "turn_2", "query_preview": "The @st.cache_data decorator fails to handle uuid.UUID objects while @st.cache works fine. The error occurs during hashing when trying to pickle UUID objects, resulting in UnhashableTypeError. The issue is in the caching mechanism's hash generation for UUID objects. /usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py hashing.py uuid.UUID st.cache_data st.cache Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'. @st.cache_data\ndef doesnt_work(some_id: uuid.UUID) -> None:\n    print(\"Nope\")", "used_extracted": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:08.482411+00:00"}
{"type": "tool_result", "step": "turn_2", "bm25_top_k": 20, "files": ["lib/streamlit/runtime/legacy_caching/hashing.py", "lib/streamlit/runtime/caching/cache_utils.py", "lib/streamlit/runtime/legacy_caching/caching.py", "lib/streamlit/runtime/caching/cache_data_api.py", "lib/streamlit/runtime/caching/cache_errors.py", "lib/streamlit/runtime/caching/hashing.py", "lib/streamlit/runtime/caching/cached_message_replay.py", "lib/streamlit/web/cli.py", "lib/streamlit/config.py", "lib/streamlit/runtime/caching/cache_resource_api.py", "lib/streamlit/runtime/caching/storage/local_disk_cache_storage.py", "lib/streamlit/runtime/caching/storage/cache_storage_protocol.py", "lib/streamlit/runtime/runtime.py", "e2e/scripts/st_markdown_in_alert_box.py", "lib/streamlit/runtime/metrics_util.py", "e2e/scripts/st_exception.py", "lib/streamlit/runtime/scriptrunner/script_runner.py", "lib/streamlit/runtime/app_session.py", "lib/streamlit/elements/arrow.py", "lib/streamlit/components/v1/components.py"], "scores": [43.35219955444336, 38.41400146484375, 37.943199157714844, 35.43239974975586, 31.0044002532959, 30.568899154663086, 28.694299697875977, 27.960399627685547, 27.353500366210938, 27.302799224853516, 26.719499588012695, 26.419099807739258, 25.60700035095215, 24.86639976501465, 24.01490020751953, 23.94420051574707, 23.680099487304688, 23.027299880981445, 19.934099197387695, 19.298999786376953], "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:08.510134+00:00"}
{"type": "token_count", "step": "turn_3", "token_count": 4753, "context_size": 16384, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:08.790533+00:00"}
{"type": "prompt", "step": "turn_3", "messages": [{"role": "system", "content": "\nYou are an expert software engineer specialized in bug localization. \nYour task is to identify the files most likely to contain bugs based on bug descriptions. \nYou have access to several tools to help you in this task. \nFrom the files you have seen, you will select 10 files that you believe are most likely to contain the bug.\n"}, {"role": "user", "content": "\n<bug_description>\n`@st.cache_data` cannot handle UUID objects (but `@st.cache` can) ### Checklist\r\n\r\n- [X] I have searched the [existing issues](https://github.com/streamlit/streamlit/issues) for similar issues.\r\n- [X] I added a very descriptive title to this issue.\r\n- [X] I have provided sufficient information below to help reproduce this issue.\r\n\r\n### Summary\r\n\r\nIt looks like the \"new\" `@st.cache_data` decorator chokes on `uuid.UUID` objects, while the deprecated `@st.cache` seems to handle them just fine; see minimal example.\r\n\r\n\r\n### Reproducible Code Example\r\n\r\n```Python\r\nimport streamlit as st\r\nimport uuid\r\n\r\n\r\n@st.cache\r\ndef works(some_id: uuid.UUID) -> None:\r\n    print(\"Works\")\r\n\r\n\r\n@st.cache_data\r\ndef doesnt_work(some_id: uuid.UUID) -> None:\r\n    print(\"Nope\")\r\n\r\n\r\nsome_id = uuid.uuid4()\r\n\r\nworks(some_id)\r\ndoesnt_work(some_id)\r\n```\r\n\r\n\r\n### Steps To Reproduce\r\n\r\n_No response_\r\n\r\n### Expected Behavior\r\n\r\n_No response_\r\n\r\n### Current Behavior\r\n\r\nThe minimal example above produces the following output:\r\n\r\n```\r\n2023-04-06 10:46:30.563 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\r\n2023-04-06 10:46:30.678 \r\n  Warning: to view this Streamlit app on a browser, run it with the following\r\n  command:\r\n\r\n    streamlit run /Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py [ARGUMENTS]\r\n2023-04-06 10:46:30.680 `st.cache` is deprecated. Please use one of Streamlit's new caching commands,\r\n`st.cache_data` or `st.cache_resource`.\r\n\r\nMore information [in our docs](https://docs.streamlit.io/library/advanced-features/caching).\r\n2023-04-06 10:46:30.681 No runtime found, using MemoryCacheStorageManager\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\r\n    reduce_data = obj.__reduce__()\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\r\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\r\nTypeError: cannot pickle 'function' object\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py\", line 20, in <module>\r\n    doesnt_work(some_id)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 194, in wrapper\r\n    return cached_func(*args, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 223, in __call__\r\n    return self._get_or_create_cached_value(args, kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 237, in _get_or_create_cached_value\r\n    value_key = _make_value_key(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 381, in _make_value_key\r\n    raise UnhashableParamError(cache_type, func, arg_name, arg_value, exc)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableParamError: Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n\r\nTo address this, you can tell Streamlit not to hash this argument by adding a\r\nleading underscore to the argument's name in the function signature:\r\n\r\n\\\\```\r\n@st.cache_data\r\ndef doesnt_work(_some_id, ...):\r\n    ...\r\n\\\\```\r\n            \r\nWorks\r\n```\r\n\r\n### Is this a regression?\r\n\r\n- [ ] Yes, this used to work in a previous version.\r\n\r\n### Debug info\r\n\r\n- Streamlit version: 1.20.0\r\n- Python version: 3.10.10\r\n- Operating System: macOS 13.2.1 (22D68)\r\n- Browser: —\r\n- Virtual environment: conda\r\n\r\n\r\n### Additional Information\r\n\r\nThe root of the problems seems to be this:\r\n```\r\nCannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n```\r\nWhich is a little strange because pickling and hashing `UUID` objects does not seem to be a problem in general:\r\n```python\r\n>>> import pickle\r\n>>> import uuid\r\n>>> pickle.dumps(uuid.uuid4())\r\nb'\\\\x80\\\\x04\\\\x950\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x8c\\\\x04uuid\\\\x94\\\\x8c\\\\x04UUID\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94\\\\x8c\\\\x03int\\\\x94\\\\x8a\\\\x10\\\\xa8\\\\x0eL\\\\x84\\\\x14\\\\xd9\\\\xcf\\\\x8d\\\\xae@M\\\\x9e\\\\x11\\\\xb0\\\\x9cvsb.'\r\n>>> hash(uuid.uuid4())\r\n1532964488252874118\r\n```\r\n\r\nA simple workaround for now is to cast `UUID` objects to strings (which are cacheable also with `@st.cache_data`), but of course it would be nicer if that were not necessary :)\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] Yes, I am willing to submit a PR!\n</bug_description>\n\nThe repository name is:\n<repo_name>\nstreamlit/streamlit\n</repo_name>\n\nYou have access to the following tools:\n\n* extract_relevant() -> Retrieve the most relevant info from the bug. Returns a JSON object with explanation, relevant code snippets, error messages and file paths mentioned in the bug. *\n\nYou must use these tools to find 10 files that are most likely to contain the bug. Start by analyzing the issue description and then decide which tool to use first.\nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}, {"role": "assistant", "content": "extracted info: {'explanation': \"The @st.cache_data decorator fails to handle uuid.UUID objects while @st.cache works fine. The error occurs during hashing when trying to pickle UUID objects, resulting in UnhashableTypeError. The issue is in the caching mechanism's hash generation for UUID objects.\", 'path': '/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py', 'filename': 'hashing.py', 'identifiers': ['uuid.UUID', 'st.cache_data', 'st.cache'], 'code snippet': '@st.cache_data\\ndef doesnt_work(some_id: uuid.UUID) -> None:\\n    print(\"Nope\")', 'stacktrace': 'Traceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\\n    reduce_data = obj.__reduce__()\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\\nTypeError: cannot pickle \\'function\\' object\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\\n    update_hash(\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\\n    ch.update(hasher, val)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\\n    raise UnhashableTypeError() from ex\\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError', 'error_message': \"Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\"}"}, {"role": "user", "content": "\nBased on the tool call results, please select your next action. Recall that you need to provide the 10 files most likely to contain bugs.\n<tool_called>\nextract_relevant\n</tool_called>\n<args>\n{}\n</args>\n\nYou have access to the following tools: \n* get_bm25_top10() -> Retrieve the top-10 best results with BM25 search. *\n* get_bm25_top20() -> Retrieve the top-20 best results with BM25 search.*\n* get_bm25_top30() -> Retrieve the top-30 best results with BM25 search. *\n \nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}, {"role": "assistant", "content": "bm25 results: {\"files\": ['lib/streamlit/runtime/legacy_caching/hashing.py', 'lib/streamlit/runtime/caching/cache_utils.py', 'lib/streamlit/runtime/legacy_caching/caching.py', 'lib/streamlit/runtime/caching/cache_data_api.py', 'lib/streamlit/runtime/caching/cache_errors.py', 'lib/streamlit/runtime/caching/hashing.py', 'lib/streamlit/runtime/caching/cached_message_replay.py', 'lib/streamlit/web/cli.py', 'lib/streamlit/config.py', 'lib/streamlit/runtime/caching/cache_resource_api.py', 'lib/streamlit/runtime/caching/storage/local_disk_cache_storage.py', 'lib/streamlit/runtime/caching/storage/cache_storage_protocol.py', 'lib/streamlit/runtime/runtime.py', 'e2e/scripts/st_markdown_in_alert_box.py', 'lib/streamlit/runtime/metrics_util.py', 'e2e/scripts/st_exception.py', 'lib/streamlit/runtime/scriptrunner/script_runner.py', 'lib/streamlit/runtime/app_session.py', 'lib/streamlit/elements/arrow.py', 'lib/streamlit/components/v1/components.py'], \"scores\": [43.35219955444336, 38.41400146484375, 37.943199157714844, 35.43239974975586, 31.0044002532959, 30.568899154663086, 28.694299697875977, 27.960399627685547, 27.353500366210938, 27.302799224853516, 26.719499588012695, 26.419099807739258, 25.60700035095215, 24.86639976501465, 24.01490020751953, 23.94420051574707, 23.680099487304688, 23.027299880981445, 19.934099197387695, 19.298999786376953]}"}, {"role": "user", "content": "\nBased on the tool call results, please select your next action. Recall that you need to provide the 10 files most likely to contain bugs.\n\n<tool_called>\nget_bm25_top20\n</tool_called>\n<args>\n{'query': 'streamlit cache_data uuid hashing'}\n</args>\n\nYou have access to the following tools: \n* view_file(`file_path`) -> View the content of the specified file. *\n* view_readme() -> View the content of the README file in the repository. *\n\nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\n\nReply ONLY with the JSON response. Remember, do not try to complete the code.\n"}], "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:08.790726+00:00"}
{"type": "response", "step": "turn_3", "response": "{\"function_call\": \"view_file\", \"args\": {\"file_path\": \"lib/streamlit/runtime/caching/hashing.py\"}}", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:11.305355+00:00"}
{"type": "parse", "step": "turn_3", "method": "json", "ok": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:11.310559+00:00"}
{"type": "parse", "step": "turn_3", "parsed": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:11.310651+00:00"}
{"type": "tool_decision", "step": "turn_3_tool", "tool_name": "view_file", "tool_args": {"file_path": "lib/streamlit/runtime/caching/hashing.py"}, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:11.310711+00:00"}
{"type": "preview_filter", "step": "turn_3_tool", "file": "lib/streamlit/runtime/caching/hashing.py", "removed_lines": 45, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:11.312545+00:00"}
{"type": "tool_result", "step": "turn_3_tool", "view_file": "lib/streamlit/runtime/caching/hashing.py", "content": "\"\"\"Hashing for st.memo and st.singleton.\"\"\"\n\n# If a dataframe has more than this many rows, we consider it large and hash a sample.\n_PANDAS_ROWS_LARGE = 100000\n_PANDAS_SAMPLE_SIZE = 10000\n\n# Similar to dataframes, we also sample large numpy arrays.\n_NP_SIZE_LARGE = 1000000\n_NP_SAMPLE_SIZE = 100000\n\n# Arbitrary item to denote where we found a cycle in a hashed object.\n# This allows us to hash self-referencing lists, dictionaries, etc.\n_CYCLE_PLACEHOLDER = b\"streamlit-57R34ML17-hesamagicalponyflyingthroughthesky-CYCLE\"\n\ndef update_hash(val: Any, hasher, cache_type: CacheType) -> None:\n    \"\"\"Updates a hashlib hasher with the hash of val.\n\n    This is the main entrypoint to hashing.py.\n    \"\"\"\n    ch = _CacheFuncHasher(cache_type)\n    ch.update(hasher, val)\n\nclass _HashStack:\n    \"\"\"Stack of what has been hashed, for debug and circular reference detection.\n\n    This internally keeps 1 stack per thread.\n\n    Internally, this stores the ID of pushed objects rather than the objects\n    themselves because otherwise the \"in\" operator inside __contains__ would\n    fail for objects that don't return a boolean for \"==\" operator. For\n    example, arr == 10 where arr is a NumPy array returns another NumPy array.\n    This causes the \"in\" to crash since it expects a boolean.\n    \"\"\"\n\n    def __init__(self):\n        self._stack: collections.OrderedDict[int, List[Any]] = collections.OrderedDict()\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def push(self, val: Any):\n        self._stack[id(val)] = val\n\n    def pop(self):\n        self._stack.popitem()\n\n    def __contains__(self, val: Any):\n        return id(val) in self._stack\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ...", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:11.332074+00:00"}
{"type": "token_count", "step": "turn_3", "token_count": 5371, "context_size": 16384, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:11.608360+00:00"}
{"type": "prompt", "step": "turn_3", "messages": [{"role": "system", "content": "\nYou are an expert software engineer specialized in bug localization. \nYour task is to identify the files most likely to contain bugs based on bug descriptions. \nYou have access to several tools to help you in this task. \nFrom the files you have seen, you will select 10 files that you believe are most likely to contain the bug.\n"}, {"role": "user", "content": "\n<bug_description>\n`@st.cache_data` cannot handle UUID objects (but `@st.cache` can) ### Checklist\r\n\r\n- [X] I have searched the [existing issues](https://github.com/streamlit/streamlit/issues) for similar issues.\r\n- [X] I added a very descriptive title to this issue.\r\n- [X] I have provided sufficient information below to help reproduce this issue.\r\n\r\n### Summary\r\n\r\nIt looks like the \"new\" `@st.cache_data` decorator chokes on `uuid.UUID` objects, while the deprecated `@st.cache` seems to handle them just fine; see minimal example.\r\n\r\n\r\n### Reproducible Code Example\r\n\r\n```Python\r\nimport streamlit as st\r\nimport uuid\r\n\r\n\r\n@st.cache\r\ndef works(some_id: uuid.UUID) -> None:\r\n    print(\"Works\")\r\n\r\n\r\n@st.cache_data\r\ndef doesnt_work(some_id: uuid.UUID) -> None:\r\n    print(\"Nope\")\r\n\r\n\r\nsome_id = uuid.uuid4()\r\n\r\nworks(some_id)\r\ndoesnt_work(some_id)\r\n```\r\n\r\n\r\n### Steps To Reproduce\r\n\r\n_No response_\r\n\r\n### Expected Behavior\r\n\r\n_No response_\r\n\r\n### Current Behavior\r\n\r\nThe minimal example above produces the following output:\r\n\r\n```\r\n2023-04-06 10:46:30.563 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\r\n2023-04-06 10:46:30.678 \r\n  Warning: to view this Streamlit app on a browser, run it with the following\r\n  command:\r\n\r\n    streamlit run /Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py [ARGUMENTS]\r\n2023-04-06 10:46:30.680 `st.cache` is deprecated. Please use one of Streamlit's new caching commands,\r\n`st.cache_data` or `st.cache_resource`.\r\n\r\nMore information [in our docs](https://docs.streamlit.io/library/advanced-features/caching).\r\n2023-04-06 10:46:30.681 No runtime found, using MemoryCacheStorageManager\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\r\n    reduce_data = obj.__reduce__()\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\r\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\r\nTypeError: cannot pickle 'function' object\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py\", line 20, in <module>\r\n    doesnt_work(some_id)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 194, in wrapper\r\n    return cached_func(*args, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 223, in __call__\r\n    return self._get_or_create_cached_value(args, kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 237, in _get_or_create_cached_value\r\n    value_key = _make_value_key(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 381, in _make_value_key\r\n    raise UnhashableParamError(cache_type, func, arg_name, arg_value, exc)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableParamError: Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n\r\nTo address this, you can tell Streamlit not to hash this argument by adding a\r\nleading underscore to the argument's name in the function signature:\r\n\r\n\\\\```\r\n@st.cache_data\r\ndef doesnt_work(_some_id, ...):\r\n    ...\r\n\\\\```\r\n            \r\nWorks\r\n```\r\n\r\n### Is this a regression?\r\n\r\n- [ ] Yes, this used to work in a previous version.\r\n\r\n### Debug info\r\n\r\n- Streamlit version: 1.20.0\r\n- Python version: 3.10.10\r\n- Operating System: macOS 13.2.1 (22D68)\r\n- Browser: —\r\n- Virtual environment: conda\r\n\r\n\r\n### Additional Information\r\n\r\nThe root of the problems seems to be this:\r\n```\r\nCannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n```\r\nWhich is a little strange because pickling and hashing `UUID` objects does not seem to be a problem in general:\r\n```python\r\n>>> import pickle\r\n>>> import uuid\r\n>>> pickle.dumps(uuid.uuid4())\r\nb'\\\\x80\\\\x04\\\\x950\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x8c\\\\x04uuid\\\\x94\\\\x8c\\\\x04UUID\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94\\\\x8c\\\\x03int\\\\x94\\\\x8a\\\\x10\\\\xa8\\\\x0eL\\\\x84\\\\x14\\\\xd9\\\\xcf\\\\x8d\\\\xae@M\\\\x9e\\\\x11\\\\xb0\\\\x9cvsb.'\r\n>>> hash(uuid.uuid4())\r\n1532964488252874118\r\n```\r\n\r\nA simple workaround for now is to cast `UUID` objects to strings (which are cacheable also with `@st.cache_data`), but of course it would be nicer if that were not necessary :)\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] Yes, I am willing to submit a PR!\n</bug_description>\n\nThe repository name is:\n<repo_name>\nstreamlit/streamlit\n</repo_name>\n\nYou have access to the following tools:\n\n* extract_relevant() -> Retrieve the most relevant info from the bug. Returns a JSON object with explanation, relevant code snippets, error messages and file paths mentioned in the bug. *\n\nYou must use these tools to find 10 files that are most likely to contain the bug. Start by analyzing the issue description and then decide which tool to use first.\nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}, {"role": "assistant", "content": "extracted info: {'explanation': \"The @st.cache_data decorator fails to handle uuid.UUID objects while @st.cache works fine. The error occurs during hashing when trying to pickle UUID objects, resulting in UnhashableTypeError. The issue is in the caching mechanism's hash generation for UUID objects.\", 'path': '/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py', 'filename': 'hashing.py', 'identifiers': ['uuid.UUID', 'st.cache_data', 'st.cache'], 'code snippet': '@st.cache_data\\ndef doesnt_work(some_id: uuid.UUID) -> None:\\n    print(\"Nope\")', 'stacktrace': 'Traceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\\n    reduce_data = obj.__reduce__()\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\\nTypeError: cannot pickle \\'function\\' object\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\\n    update_hash(\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\\n    ch.update(hasher, val)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\\n    raise UnhashableTypeError() from ex\\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError', 'error_message': \"Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\"}"}, {"role": "user", "content": "\nBased on the tool call results, please select your next action. Recall that you need to provide the 10 files most likely to contain bugs.\n<tool_called>\nextract_relevant\n</tool_called>\n<args>\n{}\n</args>\n\nYou have access to the following tools: \n* get_bm25_top10() -> Retrieve the top-10 best results with BM25 search. *\n* get_bm25_top20() -> Retrieve the top-20 best results with BM25 search.*\n* get_bm25_top30() -> Retrieve the top-30 best results with BM25 search. *\n \nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}, {"role": "assistant", "content": "bm25 results: {\"files\": ['lib/streamlit/runtime/legacy_caching/hashing.py', 'lib/streamlit/runtime/caching/cache_utils.py', 'lib/streamlit/runtime/legacy_caching/caching.py', 'lib/streamlit/runtime/caching/cache_data_api.py', 'lib/streamlit/runtime/caching/cache_errors.py', 'lib/streamlit/runtime/caching/hashing.py', 'lib/streamlit/runtime/caching/cached_message_replay.py', 'lib/streamlit/web/cli.py', 'lib/streamlit/config.py', 'lib/streamlit/runtime/caching/cache_resource_api.py', 'lib/streamlit/runtime/caching/storage/local_disk_cache_storage.py', 'lib/streamlit/runtime/caching/storage/cache_storage_protocol.py', 'lib/streamlit/runtime/runtime.py', 'e2e/scripts/st_markdown_in_alert_box.py', 'lib/streamlit/runtime/metrics_util.py', 'e2e/scripts/st_exception.py', 'lib/streamlit/runtime/scriptrunner/script_runner.py', 'lib/streamlit/runtime/app_session.py', 'lib/streamlit/elements/arrow.py', 'lib/streamlit/components/v1/components.py'], \"scores\": [43.35219955444336, 38.41400146484375, 37.943199157714844, 35.43239974975586, 31.0044002532959, 30.568899154663086, 28.694299697875977, 27.960399627685547, 27.353500366210938, 27.302799224853516, 26.719499588012695, 26.419099807739258, 25.60700035095215, 24.86639976501465, 24.01490020751953, 23.94420051574707, 23.680099487304688, 23.027299880981445, 19.934099197387695, 19.298999786376953]}"}, {"role": "user", "content": "\nBased on the tool call results, please select your next action. Recall that you need to provide the 10 files most likely to contain bugs.\n\n<tool_called>\nget_bm25_top20\n</tool_called>\n<args>\n{'query': 'streamlit cache_data uuid hashing'}\n</args>\n\nYou have access to the following tools: \n* view_file(`file_path`) -> View the content of the specified file. *\n* view_readme() -> View the content of the README file in the repository. *\n\nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\n\nReply ONLY with the JSON response. Remember, do not try to complete the code.\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/caching/hashing.py: \"\"\"Hashing for st.memo and st.singleton.\"\"\"\n\n# If a dataframe has more than this many rows, we consider it large and hash a sample.\n_PANDAS_ROWS_LARGE = 100000\n_PANDAS_SAMPLE_SIZE = 10000\n\n# Similar to dataframes, we also sample large numpy arrays.\n_NP_SIZE_LARGE = 1000000\n_NP_SAMPLE_SIZE = 100000\n\n# Arbitrary item to denote where we found a cycle in a hashed object.\n# This allows us to hash self-referencing lists, dictionaries, etc.\n_CYCLE_PLACEHOLDER = b\"streamlit-57R34ML17-hesamagicalponyflyingthroughthesky-CYCLE\"\n\ndef update_hash(val: Any, hasher, cache_type: CacheType) -> None:\n    \"\"\"Updates a hashlib hasher with the hash of val.\n\n    This is the main entrypoint to hashing.py.\n    \"\"\"\n    ch = _CacheFuncHasher(cache_type)\n    ch.update(hasher, val)\n\nclass _HashStack:\n    \"\"\"Stack of what has been hashed, for debug and circular reference detection.\n\n    This internally keeps 1 stack per thread.\n\n    Internally, this stores the ID of pushed objects rather than the objects\n    themselves because otherwise the \"in\" operator inside __contains__ would\n    fail for objects that don't return a boolean for \"==\" operator. For\n    example, arr == 10 where arr is a NumPy array returns another NumPy array.\n    This causes the \"in\" to crash since it expects a boolean.\n    \"\"\"\n\n    def __init__(self):\n        self._stack: collections.OrderedDict[int, List[Any]] = collections.OrderedDict()\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def push(self, val: Any):\n        self._stack[id(val)] = val\n\n    def pop(self):\n        self._stack.popitem()\n\n    def __contains__(self, val: Any):\n        return id(val) in self._stack\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}], "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:11.608539+00:00"}
{"type": "response", "step": "turn_3", "response": "{\"function_call\":\"view_file\",\"args\":{\"file_path\":\"lib/streamlit/runtime/caching/cache_utils.py\"}}", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:13.877015+00:00"}
{"type": "parse", "step": "turn_3", "method": "json", "ok": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:13.882272+00:00"}
{"type": "parse", "step": "turn_3", "parsed": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:13.882364+00:00"}
{"type": "tool_decision", "step": "turn_3_tool", "tool_name": "view_file", "tool_args": {"file_path": "lib/streamlit/runtime/caching/cache_utils.py"}, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:13.882484+00:00"}
{"type": "preview_filter", "step": "turn_3_tool", "file": "lib/streamlit/runtime/caching/cache_utils.py", "removed_lines": 46, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:13.884563+00:00"}
{"type": "tool_result", "step": "turn_3_tool", "view_file": "lib/streamlit/runtime/caching/cache_utils.py", "content": "\"\"\"Common cache logic shared by st.cache_data and st.cache_resource.\"\"\"\n\nfrom streamlit.runtime.caching.cache_errors import (\n    CacheError,\n    CacheKeyNotFoundError,\n    UnevaluatedDataFrameError,\n    UnhashableParamError,\n    UnhashableTypeError,\n    UnserializableReturnValueError,\n    get_cached_func_name_md,\n)\nfrom streamlit.runtime.caching.cached_message_replay import (\n    CachedMessageReplayContext,\n    CachedResult,\n    MsgData,\n    replay_cached_messages,\n)\n\n_LOGGER = get_logger(__name__)\n\n# The timer function we use with TTLCache. This is the default timer func, but\n# is exposed here as a constant so that it can be patched in unit tests.\nTTLCACHE_TIMER = time.monotonic\n\n@overload\ndef ttl_to_seconds(\n    ttl: float | timedelta | None, *, coerce_none_to_inf: Literal[False]\n) -> float | None:\n    ...\n\n@overload\ndef ttl_to_seconds(ttl: float | timedelta | None) -> float:\n    ...\n\ndef ttl_to_seconds(\n    ttl: float | timedelta | None, *, coerce_none_to_inf: bool = True\n) -> float | None:\n    \"\"\"\n    Convert a ttl value to a float representing \"number of seconds\".\n    \"\"\"\n    if coerce_none_to_inf and ttl is None:\n        return math.inf\n    if isinstance(ttl, timedelta):\n        return ttl.total_seconds()\n    return ttl\n\n# We show a special \"UnevaluatedDataFrame\" warning for cached funcs\n# that attempt to return one of these unserializable types:\nUNEVALUATED_DATAFRAME_TYPES = (\n    \"snowflake.snowpark.table.Table\",\n    \"snowflake.snowpark.dataframe.DataFrame\",\n    \"pyspark.sql.dataframe.DataFrame\",\n)\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ...", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:13.908464+00:00"}
{"type": "token_count", "step": "turn_3", "token_count": 5917, "context_size": 16384, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:14.188363+00:00"}
{"type": "prompt", "step": "turn_3", "messages": [{"role": "system", "content": "\nYou are an expert software engineer specialized in bug localization. \nYour task is to identify the files most likely to contain bugs based on bug descriptions. \nYou have access to several tools to help you in this task. \nFrom the files you have seen, you will select 10 files that you believe are most likely to contain the bug.\n"}, {"role": "user", "content": "\n<bug_description>\n`@st.cache_data` cannot handle UUID objects (but `@st.cache` can) ### Checklist\r\n\r\n- [X] I have searched the [existing issues](https://github.com/streamlit/streamlit/issues) for similar issues.\r\n- [X] I added a very descriptive title to this issue.\r\n- [X] I have provided sufficient information below to help reproduce this issue.\r\n\r\n### Summary\r\n\r\nIt looks like the \"new\" `@st.cache_data` decorator chokes on `uuid.UUID` objects, while the deprecated `@st.cache` seems to handle them just fine; see minimal example.\r\n\r\n\r\n### Reproducible Code Example\r\n\r\n```Python\r\nimport streamlit as st\r\nimport uuid\r\n\r\n\r\n@st.cache\r\ndef works(some_id: uuid.UUID) -> None:\r\n    print(\"Works\")\r\n\r\n\r\n@st.cache_data\r\ndef doesnt_work(some_id: uuid.UUID) -> None:\r\n    print(\"Nope\")\r\n\r\n\r\nsome_id = uuid.uuid4()\r\n\r\nworks(some_id)\r\ndoesnt_work(some_id)\r\n```\r\n\r\n\r\n### Steps To Reproduce\r\n\r\n_No response_\r\n\r\n### Expected Behavior\r\n\r\n_No response_\r\n\r\n### Current Behavior\r\n\r\nThe minimal example above produces the following output:\r\n\r\n```\r\n2023-04-06 10:46:30.563 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\r\n2023-04-06 10:46:30.678 \r\n  Warning: to view this Streamlit app on a browser, run it with the following\r\n  command:\r\n\r\n    streamlit run /Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py [ARGUMENTS]\r\n2023-04-06 10:46:30.680 `st.cache` is deprecated. Please use one of Streamlit's new caching commands,\r\n`st.cache_data` or `st.cache_resource`.\r\n\r\nMore information [in our docs](https://docs.streamlit.io/library/advanced-features/caching).\r\n2023-04-06 10:46:30.681 No runtime found, using MemoryCacheStorageManager\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\r\n    reduce_data = obj.__reduce__()\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\r\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\r\nTypeError: cannot pickle 'function' object\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py\", line 20, in <module>\r\n    doesnt_work(some_id)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 194, in wrapper\r\n    return cached_func(*args, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 223, in __call__\r\n    return self._get_or_create_cached_value(args, kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 237, in _get_or_create_cached_value\r\n    value_key = _make_value_key(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 381, in _make_value_key\r\n    raise UnhashableParamError(cache_type, func, arg_name, arg_value, exc)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableParamError: Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n\r\nTo address this, you can tell Streamlit not to hash this argument by adding a\r\nleading underscore to the argument's name in the function signature:\r\n\r\n\\\\```\r\n@st.cache_data\r\ndef doesnt_work(_some_id, ...):\r\n    ...\r\n\\\\```\r\n            \r\nWorks\r\n```\r\n\r\n### Is this a regression?\r\n\r\n- [ ] Yes, this used to work in a previous version.\r\n\r\n### Debug info\r\n\r\n- Streamlit version: 1.20.0\r\n- Python version: 3.10.10\r\n- Operating System: macOS 13.2.1 (22D68)\r\n- Browser: —\r\n- Virtual environment: conda\r\n\r\n\r\n### Additional Information\r\n\r\nThe root of the problems seems to be this:\r\n```\r\nCannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n```\r\nWhich is a little strange because pickling and hashing `UUID` objects does not seem to be a problem in general:\r\n```python\r\n>>> import pickle\r\n>>> import uuid\r\n>>> pickle.dumps(uuid.uuid4())\r\nb'\\\\x80\\\\x04\\\\x950\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x8c\\\\x04uuid\\\\x94\\\\x8c\\\\x04UUID\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94\\\\x8c\\\\x03int\\\\x94\\\\x8a\\\\x10\\\\xa8\\\\x0eL\\\\x84\\\\x14\\\\xd9\\\\xcf\\\\x8d\\\\xae@M\\\\x9e\\\\x11\\\\xb0\\\\x9cvsb.'\r\n>>> hash(uuid.uuid4())\r\n1532964488252874118\r\n```\r\n\r\nA simple workaround for now is to cast `UUID` objects to strings (which are cacheable also with `@st.cache_data`), but of course it would be nicer if that were not necessary :)\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] Yes, I am willing to submit a PR!\n</bug_description>\n\nThe repository name is:\n<repo_name>\nstreamlit/streamlit\n</repo_name>\n\nYou have access to the following tools:\n\n* extract_relevant() -> Retrieve the most relevant info from the bug. Returns a JSON object with explanation, relevant code snippets, error messages and file paths mentioned in the bug. *\n\nYou must use these tools to find 10 files that are most likely to contain the bug. Start by analyzing the issue description and then decide which tool to use first.\nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}, {"role": "assistant", "content": "extracted info: {'explanation': \"The @st.cache_data decorator fails to handle uuid.UUID objects while @st.cache works fine. The error occurs during hashing when trying to pickle UUID objects, resulting in UnhashableTypeError. The issue is in the caching mechanism's hash generation for UUID objects.\", 'path': '/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py', 'filename': 'hashing.py', 'identifiers': ['uuid.UUID', 'st.cache_data', 'st.cache'], 'code snippet': '@st.cache_data\\ndef doesnt_work(some_id: uuid.UUID) -> None:\\n    print(\"Nope\")', 'stacktrace': 'Traceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\\n    reduce_data = obj.__reduce__()\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\\nTypeError: cannot pickle \\'function\\' object\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\\n    update_hash(\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\\n    ch.update(hasher, val)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\\n    raise UnhashableTypeError() from ex\\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError', 'error_message': \"Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\"}"}, {"role": "user", "content": "\nBased on the tool call results, please select your next action. Recall that you need to provide the 10 files most likely to contain bugs.\n<tool_called>\nextract_relevant\n</tool_called>\n<args>\n{}\n</args>\n\nYou have access to the following tools: \n* get_bm25_top10() -> Retrieve the top-10 best results with BM25 search. *\n* get_bm25_top20() -> Retrieve the top-20 best results with BM25 search.*\n* get_bm25_top30() -> Retrieve the top-30 best results with BM25 search. *\n \nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}, {"role": "assistant", "content": "bm25 results: {\"files\": ['lib/streamlit/runtime/legacy_caching/hashing.py', 'lib/streamlit/runtime/caching/cache_utils.py', 'lib/streamlit/runtime/legacy_caching/caching.py', 'lib/streamlit/runtime/caching/cache_data_api.py', 'lib/streamlit/runtime/caching/cache_errors.py', 'lib/streamlit/runtime/caching/hashing.py', 'lib/streamlit/runtime/caching/cached_message_replay.py', 'lib/streamlit/web/cli.py', 'lib/streamlit/config.py', 'lib/streamlit/runtime/caching/cache_resource_api.py', 'lib/streamlit/runtime/caching/storage/local_disk_cache_storage.py', 'lib/streamlit/runtime/caching/storage/cache_storage_protocol.py', 'lib/streamlit/runtime/runtime.py', 'e2e/scripts/st_markdown_in_alert_box.py', 'lib/streamlit/runtime/metrics_util.py', 'e2e/scripts/st_exception.py', 'lib/streamlit/runtime/scriptrunner/script_runner.py', 'lib/streamlit/runtime/app_session.py', 'lib/streamlit/elements/arrow.py', 'lib/streamlit/components/v1/components.py'], \"scores\": [43.35219955444336, 38.41400146484375, 37.943199157714844, 35.43239974975586, 31.0044002532959, 30.568899154663086, 28.694299697875977, 27.960399627685547, 27.353500366210938, 27.302799224853516, 26.719499588012695, 26.419099807739258, 25.60700035095215, 24.86639976501465, 24.01490020751953, 23.94420051574707, 23.680099487304688, 23.027299880981445, 19.934099197387695, 19.298999786376953]}"}, {"role": "user", "content": "\nBased on the tool call results, please select your next action. Recall that you need to provide the 10 files most likely to contain bugs.\n\n<tool_called>\nget_bm25_top20\n</tool_called>\n<args>\n{'query': 'streamlit cache_data uuid hashing'}\n</args>\n\nYou have access to the following tools: \n* view_file(`file_path`) -> View the content of the specified file. *\n* view_readme() -> View the content of the README file in the repository. *\n\nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\n\nReply ONLY with the JSON response. Remember, do not try to complete the code.\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/caching/hashing.py: \"\"\"Hashing for st.memo and st.singleton.\"\"\"\n\n# If a dataframe has more than this many rows, we consider it large and hash a sample.\n_PANDAS_ROWS_LARGE = 100000\n_PANDAS_SAMPLE_SIZE = 10000\n\n# Similar to dataframes, we also sample large numpy arrays.\n_NP_SIZE_LARGE = 1000000\n_NP_SAMPLE_SIZE = 100000\n\n# Arbitrary item to denote where we found a cycle in a hashed object.\n# This allows us to hash self-referencing lists, dictionaries, etc.\n_CYCLE_PLACEHOLDER = b\"streamlit-57R34ML17-hesamagicalponyflyingthroughthesky-CYCLE\"\n\ndef update_hash(val: Any, hasher, cache_type: CacheType) -> None:\n    \"\"\"Updates a hashlib hasher with the hash of val.\n\n    This is the main entrypoint to hashing.py.\n    \"\"\"\n    ch = _CacheFuncHasher(cache_type)\n    ch.update(hasher, val)\n\nclass _HashStack:\n    \"\"\"Stack of what has been hashed, for debug and circular reference detection.\n\n    This internally keeps 1 stack per thread.\n\n    Internally, this stores the ID of pushed objects rather than the objects\n    themselves because otherwise the \"in\" operator inside __contains__ would\n    fail for objects that don't return a boolean for \"==\" operator. For\n    example, arr == 10 where arr is a NumPy array returns another NumPy array.\n    This causes the \"in\" to crash since it expects a boolean.\n    \"\"\"\n\n    def __init__(self):\n        self._stack: collections.OrderedDict[int, List[Any]] = collections.OrderedDict()\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def push(self, val: Any):\n        self._stack[id(val)] = val\n\n    def pop(self):\n        self._stack.popitem()\n\n    def __contains__(self, val: Any):\n        return id(val) in self._stack\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/caching/cache_utils.py: \"\"\"Common cache logic shared by st.cache_data and st.cache_resource.\"\"\"\n\nfrom streamlit.runtime.caching.cache_errors import (\n    CacheError,\n    CacheKeyNotFoundError,\n    UnevaluatedDataFrameError,\n    UnhashableParamError,\n    UnhashableTypeError,\n    UnserializableReturnValueError,\n    get_cached_func_name_md,\n)\nfrom streamlit.runtime.caching.cached_message_replay import (\n    CachedMessageReplayContext,\n    CachedResult,\n    MsgData,\n    replay_cached_messages,\n)\n\n_LOGGER = get_logger(__name__)\n\n# The timer function we use with TTLCache. This is the default timer func, but\n# is exposed here as a constant so that it can be patched in unit tests.\nTTLCACHE_TIMER = time.monotonic\n\n@overload\ndef ttl_to_seconds(\n    ttl: float | timedelta | None, *, coerce_none_to_inf: Literal[False]\n) -> float | None:\n    ...\n\n@overload\ndef ttl_to_seconds(ttl: float | timedelta | None) -> float:\n    ...\n\ndef ttl_to_seconds(\n    ttl: float | timedelta | None, *, coerce_none_to_inf: bool = True\n) -> float | None:\n    \"\"\"\n    Convert a ttl value to a float representing \"number of seconds\".\n    \"\"\"\n    if coerce_none_to_inf and ttl is None:\n        return math.inf\n    if isinstance(ttl, timedelta):\n        return ttl.total_seconds()\n    return ttl\n\n# We show a special \"UnevaluatedDataFrame\" warning for cached funcs\n# that attempt to return one of these unserializable types:\nUNEVALUATED_DATAFRAME_TYPES = (\n    \"snowflake.snowpark.table.Table\",\n    \"snowflake.snowpark.dataframe.DataFrame\",\n    \"pyspark.sql.dataframe.DataFrame\",\n)\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}], "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:14.188550+00:00"}
{"type": "response", "step": "turn_3", "response": "{\"function_call\":\"view_file\",\"args\":{\"file_path\":\"lib/streamlit/runtime/legacy_caching/hashing.py\"}}", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:16.556135+00:00"}
{"type": "parse", "step": "turn_3", "method": "json", "ok": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:16.561428+00:00"}
{"type": "parse", "step": "turn_3", "parsed": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:16.561509+00:00"}
{"type": "tool_decision", "step": "turn_3_tool", "tool_name": "view_file", "tool_args": {"file_path": "lib/streamlit/runtime/legacy_caching/hashing.py"}, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:16.561569+00:00"}
{"type": "preview_filter", "step": "turn_3_tool", "file": "lib/streamlit/runtime/legacy_caching/hashing.py", "removed_lines": 65, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:16.564069+00:00"}
{"type": "tool_result", "step": "turn_3_tool", "view_file": "lib/streamlit/runtime/legacy_caching/hashing.py", "content": "\"\"\"A hashing utility for code.\"\"\"\n\n# If a dataframe has more than this many rows, we consider it large and hash a sample.\n_PANDAS_ROWS_LARGE = 100000\n_PANDAS_SAMPLE_SIZE = 10000\n\n# Similar to dataframes, we also sample large numpy arrays.\n_NP_SIZE_LARGE = 1000000\n_NP_SAMPLE_SIZE = 100000\n\n# Arbitrary item to denote where we found a cycle in a hashed object.\n# This allows us to hash self-referencing lists, dictionaries, etc.\n_CYCLE_PLACEHOLDER = b\"streamlit-57R34ML17-hesamagicalponyflyingthroughthesky-CYCLE\"\n\n# This needs to be initialized lazily to avoid calling config.get_option() and\n# thus initializing config options when this file is first imported.\n_FOLDER_BLACK_LIST = None\n\n# FFI objects (objects that interface with C libraries) can be any of these types:\n_FFI_TYPE_NAMES = [\n    \"_cffi_backend.FFI\",\n    \"builtins.CompiledFFI\",\n]\n\n# KERAS objects can be any of these types:\n_KERAS_TYPE_NAMES = [\n    \"keras.engine.training.Model\",\n    \"tensorflow.python.keras.engine.training.Model\",\n    \"tensorflow.python.keras.engine.functional.Functional\",\n]\n\nContext = collections.namedtuple(\"Context\", [\"globals\", \"cells\", \"varnames\"])\n\n# Mapping of types or fully qualified names to hash functions. This is used to\n# override the behavior of the hasher inside Streamlit's caching mechanism:\n# when the hasher encounters an object, it will first check to see if its type\n# matches a key in this dict and, if so, will use the provided function to\n# generate a hash for it.\nHashFuncsDict = Dict[Union[str, Type[Any]], Callable[[Any], Any]]\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ...", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:16.623220+00:00"}
{"type": "token_count", "step": "turn_3", "token_count": 6495, "context_size": 16384, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:16.912883+00:00"}
{"type": "prompt", "step": "turn_3", "messages": [{"role": "system", "content": "\nYou are an expert software engineer specialized in bug localization. \nYour task is to identify the files most likely to contain bugs based on bug descriptions. \nYou have access to several tools to help you in this task. \nFrom the files you have seen, you will select 10 files that you believe are most likely to contain the bug.\n"}, {"role": "user", "content": "\n<bug_description>\n`@st.cache_data` cannot handle UUID objects (but `@st.cache` can) ### Checklist\r\n\r\n- [X] I have searched the [existing issues](https://github.com/streamlit/streamlit/issues) for similar issues.\r\n- [X] I added a very descriptive title to this issue.\r\n- [X] I have provided sufficient information below to help reproduce this issue.\r\n\r\n### Summary\r\n\r\nIt looks like the \"new\" `@st.cache_data` decorator chokes on `uuid.UUID` objects, while the deprecated `@st.cache` seems to handle them just fine; see minimal example.\r\n\r\n\r\n### Reproducible Code Example\r\n\r\n```Python\r\nimport streamlit as st\r\nimport uuid\r\n\r\n\r\n@st.cache\r\ndef works(some_id: uuid.UUID) -> None:\r\n    print(\"Works\")\r\n\r\n\r\n@st.cache_data\r\ndef doesnt_work(some_id: uuid.UUID) -> None:\r\n    print(\"Nope\")\r\n\r\n\r\nsome_id = uuid.uuid4()\r\n\r\nworks(some_id)\r\ndoesnt_work(some_id)\r\n```\r\n\r\n\r\n### Steps To Reproduce\r\n\r\n_No response_\r\n\r\n### Expected Behavior\r\n\r\n_No response_\r\n\r\n### Current Behavior\r\n\r\nThe minimal example above produces the following output:\r\n\r\n```\r\n2023-04-06 10:46:30.563 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\r\n2023-04-06 10:46:30.678 \r\n  Warning: to view this Streamlit app on a browser, run it with the following\r\n  command:\r\n\r\n    streamlit run /Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py [ARGUMENTS]\r\n2023-04-06 10:46:30.680 `st.cache` is deprecated. Please use one of Streamlit's new caching commands,\r\n`st.cache_data` or `st.cache_resource`.\r\n\r\nMore information [in our docs](https://docs.streamlit.io/library/advanced-features/caching).\r\n2023-04-06 10:46:30.681 No runtime found, using MemoryCacheStorageManager\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\r\n    reduce_data = obj.__reduce__()\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\r\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\r\nTypeError: cannot pickle 'function' object\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py\", line 20, in <module>\r\n    doesnt_work(some_id)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 194, in wrapper\r\n    return cached_func(*args, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 223, in __call__\r\n    return self._get_or_create_cached_value(args, kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 237, in _get_or_create_cached_value\r\n    value_key = _make_value_key(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 381, in _make_value_key\r\n    raise UnhashableParamError(cache_type, func, arg_name, arg_value, exc)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableParamError: Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n\r\nTo address this, you can tell Streamlit not to hash this argument by adding a\r\nleading underscore to the argument's name in the function signature:\r\n\r\n\\\\```\r\n@st.cache_data\r\ndef doesnt_work(_some_id, ...):\r\n    ...\r\n\\\\```\r\n            \r\nWorks\r\n```\r\n\r\n### Is this a regression?\r\n\r\n- [ ] Yes, this used to work in a previous version.\r\n\r\n### Debug info\r\n\r\n- Streamlit version: 1.20.0\r\n- Python version: 3.10.10\r\n- Operating System: macOS 13.2.1 (22D68)\r\n- Browser: —\r\n- Virtual environment: conda\r\n\r\n\r\n### Additional Information\r\n\r\nThe root of the problems seems to be this:\r\n```\r\nCannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n```\r\nWhich is a little strange because pickling and hashing `UUID` objects does not seem to be a problem in general:\r\n```python\r\n>>> import pickle\r\n>>> import uuid\r\n>>> pickle.dumps(uuid.uuid4())\r\nb'\\\\x80\\\\x04\\\\x950\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x8c\\\\x04uuid\\\\x94\\\\x8c\\\\x04UUID\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94\\\\x8c\\\\x03int\\\\x94\\\\x8a\\\\x10\\\\xa8\\\\x0eL\\\\x84\\\\x14\\\\xd9\\\\xcf\\\\x8d\\\\xae@M\\\\x9e\\\\x11\\\\xb0\\\\x9cvsb.'\r\n>>> hash(uuid.uuid4())\r\n1532964488252874118\r\n```\r\n\r\nA simple workaround for now is to cast `UUID` objects to strings (which are cacheable also with `@st.cache_data`), but of course it would be nicer if that were not necessary :)\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] Yes, I am willing to submit a PR!\n</bug_description>\n\nThe repository name is:\n<repo_name>\nstreamlit/streamlit\n</repo_name>\n\nYou have access to the following tools:\n\n* extract_relevant() -> Retrieve the most relevant info from the bug. Returns a JSON object with explanation, relevant code snippets, error messages and file paths mentioned in the bug. *\n\nYou must use these tools to find 10 files that are most likely to contain the bug. Start by analyzing the issue description and then decide which tool to use first.\nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}, {"role": "assistant", "content": "extracted info: {'explanation': \"The @st.cache_data decorator fails to handle uuid.UUID objects while @st.cache works fine. The error occurs during hashing when trying to pickle UUID objects, resulting in UnhashableTypeError. The issue is in the caching mechanism's hash generation for UUID objects.\", 'path': '/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py', 'filename': 'hashing.py', 'identifiers': ['uuid.UUID', 'st.cache_data', 'st.cache'], 'code snippet': '@st.cache_data\\ndef doesnt_work(some_id: uuid.UUID) -> None:\\n    print(\"Nope\")', 'stacktrace': 'Traceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\\n    reduce_data = obj.__reduce__()\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\\nTypeError: cannot pickle \\'function\\' object\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\\n    update_hash(\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\\n    ch.update(hasher, val)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\\n    raise UnhashableTypeError() from ex\\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError', 'error_message': \"Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\"}"}, {"role": "user", "content": "\nBased on the tool call results, please select your next action. Recall that you need to provide the 10 files most likely to contain bugs.\n<tool_called>\nextract_relevant\n</tool_called>\n<args>\n{}\n</args>\n\nYou have access to the following tools: \n* get_bm25_top10() -> Retrieve the top-10 best results with BM25 search. *\n* get_bm25_top20() -> Retrieve the top-20 best results with BM25 search.*\n* get_bm25_top30() -> Retrieve the top-30 best results with BM25 search. *\n \nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}, {"role": "assistant", "content": "bm25 results: {\"files\": ['lib/streamlit/runtime/legacy_caching/hashing.py', 'lib/streamlit/runtime/caching/cache_utils.py', 'lib/streamlit/runtime/legacy_caching/caching.py', 'lib/streamlit/runtime/caching/cache_data_api.py', 'lib/streamlit/runtime/caching/cache_errors.py', 'lib/streamlit/runtime/caching/hashing.py', 'lib/streamlit/runtime/caching/cached_message_replay.py', 'lib/streamlit/web/cli.py', 'lib/streamlit/config.py', 'lib/streamlit/runtime/caching/cache_resource_api.py', 'lib/streamlit/runtime/caching/storage/local_disk_cache_storage.py', 'lib/streamlit/runtime/caching/storage/cache_storage_protocol.py', 'lib/streamlit/runtime/runtime.py', 'e2e/scripts/st_markdown_in_alert_box.py', 'lib/streamlit/runtime/metrics_util.py', 'e2e/scripts/st_exception.py', 'lib/streamlit/runtime/scriptrunner/script_runner.py', 'lib/streamlit/runtime/app_session.py', 'lib/streamlit/elements/arrow.py', 'lib/streamlit/components/v1/components.py'], \"scores\": [43.35219955444336, 38.41400146484375, 37.943199157714844, 35.43239974975586, 31.0044002532959, 30.568899154663086, 28.694299697875977, 27.960399627685547, 27.353500366210938, 27.302799224853516, 26.719499588012695, 26.419099807739258, 25.60700035095215, 24.86639976501465, 24.01490020751953, 23.94420051574707, 23.680099487304688, 23.027299880981445, 19.934099197387695, 19.298999786376953]}"}, {"role": "user", "content": "\nBased on the tool call results, please select your next action. Recall that you need to provide the 10 files most likely to contain bugs.\n\n<tool_called>\nget_bm25_top20\n</tool_called>\n<args>\n{'query': 'streamlit cache_data uuid hashing'}\n</args>\n\nYou have access to the following tools: \n* view_file(`file_path`) -> View the content of the specified file. *\n* view_readme() -> View the content of the README file in the repository. *\n\nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\n\nReply ONLY with the JSON response. Remember, do not try to complete the code.\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/caching/hashing.py: \"\"\"Hashing for st.memo and st.singleton.\"\"\"\n\n# If a dataframe has more than this many rows, we consider it large and hash a sample.\n_PANDAS_ROWS_LARGE = 100000\n_PANDAS_SAMPLE_SIZE = 10000\n\n# Similar to dataframes, we also sample large numpy arrays.\n_NP_SIZE_LARGE = 1000000\n_NP_SAMPLE_SIZE = 100000\n\n# Arbitrary item to denote where we found a cycle in a hashed object.\n# This allows us to hash self-referencing lists, dictionaries, etc.\n_CYCLE_PLACEHOLDER = b\"streamlit-57R34ML17-hesamagicalponyflyingthroughthesky-CYCLE\"\n\ndef update_hash(val: Any, hasher, cache_type: CacheType) -> None:\n    \"\"\"Updates a hashlib hasher with the hash of val.\n\n    This is the main entrypoint to hashing.py.\n    \"\"\"\n    ch = _CacheFuncHasher(cache_type)\n    ch.update(hasher, val)\n\nclass _HashStack:\n    \"\"\"Stack of what has been hashed, for debug and circular reference detection.\n\n    This internally keeps 1 stack per thread.\n\n    Internally, this stores the ID of pushed objects rather than the objects\n    themselves because otherwise the \"in\" operator inside __contains__ would\n    fail for objects that don't return a boolean for \"==\" operator. For\n    example, arr == 10 where arr is a NumPy array returns another NumPy array.\n    This causes the \"in\" to crash since it expects a boolean.\n    \"\"\"\n\n    def __init__(self):\n        self._stack: collections.OrderedDict[int, List[Any]] = collections.OrderedDict()\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def push(self, val: Any):\n        self._stack[id(val)] = val\n\n    def pop(self):\n        self._stack.popitem()\n\n    def __contains__(self, val: Any):\n        return id(val) in self._stack\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/caching/cache_utils.py: \"\"\"Common cache logic shared by st.cache_data and st.cache_resource.\"\"\"\n\nfrom streamlit.runtime.caching.cache_errors import (\n    CacheError,\n    CacheKeyNotFoundError,\n    UnevaluatedDataFrameError,\n    UnhashableParamError,\n    UnhashableTypeError,\n    UnserializableReturnValueError,\n    get_cached_func_name_md,\n)\nfrom streamlit.runtime.caching.cached_message_replay import (\n    CachedMessageReplayContext,\n    CachedResult,\n    MsgData,\n    replay_cached_messages,\n)\n\n_LOGGER = get_logger(__name__)\n\n# The timer function we use with TTLCache. This is the default timer func, but\n# is exposed here as a constant so that it can be patched in unit tests.\nTTLCACHE_TIMER = time.monotonic\n\n@overload\ndef ttl_to_seconds(\n    ttl: float | timedelta | None, *, coerce_none_to_inf: Literal[False]\n) -> float | None:\n    ...\n\n@overload\ndef ttl_to_seconds(ttl: float | timedelta | None) -> float:\n    ...\n\ndef ttl_to_seconds(\n    ttl: float | timedelta | None, *, coerce_none_to_inf: bool = True\n) -> float | None:\n    \"\"\"\n    Convert a ttl value to a float representing \"number of seconds\".\n    \"\"\"\n    if coerce_none_to_inf and ttl is None:\n        return math.inf\n    if isinstance(ttl, timedelta):\n        return ttl.total_seconds()\n    return ttl\n\n# We show a special \"UnevaluatedDataFrame\" warning for cached funcs\n# that attempt to return one of these unserializable types:\nUNEVALUATED_DATAFRAME_TYPES = (\n    \"snowflake.snowpark.table.Table\",\n    \"snowflake.snowpark.dataframe.DataFrame\",\n    \"pyspark.sql.dataframe.DataFrame\",\n)\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/legacy_caching/hashing.py: \"\"\"A hashing utility for code.\"\"\"\n\n# If a dataframe has more than this many rows, we consider it large and hash a sample.\n_PANDAS_ROWS_LARGE = 100000\n_PANDAS_SAMPLE_SIZE = 10000\n\n# Similar to dataframes, we also sample large numpy arrays.\n_NP_SIZE_LARGE = 1000000\n_NP_SAMPLE_SIZE = 100000\n\n# Arbitrary item to denote where we found a cycle in a hashed object.\n# This allows us to hash self-referencing lists, dictionaries, etc.\n_CYCLE_PLACEHOLDER = b\"streamlit-57R34ML17-hesamagicalponyflyingthroughthesky-CYCLE\"\n\n# This needs to be initialized lazily to avoid calling config.get_option() and\n# thus initializing config options when this file is first imported.\n_FOLDER_BLACK_LIST = None\n\n# FFI objects (objects that interface with C libraries) can be any of these types:\n_FFI_TYPE_NAMES = [\n    \"_cffi_backend.FFI\",\n    \"builtins.CompiledFFI\",\n]\n\n# KERAS objects can be any of these types:\n_KERAS_TYPE_NAMES = [\n    \"keras.engine.training.Model\",\n    \"tensorflow.python.keras.engine.training.Model\",\n    \"tensorflow.python.keras.engine.functional.Functional\",\n]\n\nContext = collections.namedtuple(\"Context\", [\"globals\", \"cells\", \"varnames\"])\n\n# Mapping of types or fully qualified names to hash functions. This is used to\n# override the behavior of the hasher inside Streamlit's caching mechanism:\n# when the hasher encounters an object, it will first check to see if its type\n# matches a key in this dict and, if so, will use the provided function to\n# generate a hash for it.\nHashFuncsDict = Dict[Union[str, Type[Any]], Callable[[Any], Any]]\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}], "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:16.913087+00:00"}
{"type": "response", "step": "turn_3", "response": "{\"function_call\":\"view_file\",\"args\":{\"file_path\":\"lib/streamlit/runtime/caching/cache_data_api.py\"}}", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:19.367926+00:00"}
{"type": "parse", "step": "turn_3", "method": "json", "ok": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:19.372958+00:00"}
{"type": "parse", "step": "turn_3", "parsed": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:19.373064+00:00"}
{"type": "tool_decision", "step": "turn_3_tool", "tool_name": "view_file", "tool_args": {"file_path": "lib/streamlit/runtime/caching/cache_data_api.py"}, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:19.373121+00:00"}
{"type": "preview_filter", "step": "turn_3_tool", "file": "lib/streamlit/runtime/caching/cache_data_api.py", "removed_lines": 40, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:19.375034+00:00"}
{"type": "tool_result", "step": "turn_3_tool", "view_file": "lib/streamlit/runtime/caching/cache_data_api.py", "content": "\"\"\"@st.cache_data: pickle-based caching\"\"\"\n\nfrom streamlit.runtime.caching.cache_utils import (\n    Cache,\n    CachedFuncInfo,\n    make_cached_func_wrapper,\n    ttl_to_seconds,\n)\nfrom streamlit.runtime.caching.cached_message_replay import (\n    CachedMessageReplayContext,\n    CachedResult,\n    ElementMsgData,\n    MsgData,\n    MultiCacheResults,\n)\nfrom streamlit.runtime.caching.storage import (\n    CacheStorage,\n    CacheStorageContext,\n    CacheStorageError,\n    CacheStorageKeyNotFoundError,\n    CacheStorageManager,\n)\nfrom streamlit.runtime.caching.storage.cache_storage_protocol import (\n    InvalidCacheStorageContext,\n)\nfrom streamlit.runtime.caching.storage.dummy_cache_storage import (\n    MemoryCacheStorageManager,\n)\n\n_LOGGER = get_logger(__name__)\n\nCACHE_DATA_MESSAGE_REPLAY_CTX = CachedMessageReplayContext(CacheType.DATA)\n\n# The cache persistence options we support: \"disk\" or None\nCachePersistType: TypeAlias = Union[Literal[\"disk\"], None]\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ...", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:19.411084+00:00"}
{"type": "token_count", "step": "turn_3", "token_count": 6883, "context_size": 16384, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:19.713944+00:00"}
{"type": "prompt", "step": "turn_3", "messages": [{"role": "system", "content": "\nYou are an expert software engineer specialized in bug localization. \nYour task is to identify the files most likely to contain bugs based on bug descriptions. \nYou have access to several tools to help you in this task. \nFrom the files you have seen, you will select 10 files that you believe are most likely to contain the bug.\n"}, {"role": "user", "content": "\n<bug_description>\n`@st.cache_data` cannot handle UUID objects (but `@st.cache` can) ### Checklist\r\n\r\n- [X] I have searched the [existing issues](https://github.com/streamlit/streamlit/issues) for similar issues.\r\n- [X] I added a very descriptive title to this issue.\r\n- [X] I have provided sufficient information below to help reproduce this issue.\r\n\r\n### Summary\r\n\r\nIt looks like the \"new\" `@st.cache_data` decorator chokes on `uuid.UUID` objects, while the deprecated `@st.cache` seems to handle them just fine; see minimal example.\r\n\r\n\r\n### Reproducible Code Example\r\n\r\n```Python\r\nimport streamlit as st\r\nimport uuid\r\n\r\n\r\n@st.cache\r\ndef works(some_id: uuid.UUID) -> None:\r\n    print(\"Works\")\r\n\r\n\r\n@st.cache_data\r\ndef doesnt_work(some_id: uuid.UUID) -> None:\r\n    print(\"Nope\")\r\n\r\n\r\nsome_id = uuid.uuid4()\r\n\r\nworks(some_id)\r\ndoesnt_work(some_id)\r\n```\r\n\r\n\r\n### Steps To Reproduce\r\n\r\n_No response_\r\n\r\n### Expected Behavior\r\n\r\n_No response_\r\n\r\n### Current Behavior\r\n\r\nThe minimal example above produces the following output:\r\n\r\n```\r\n2023-04-06 10:46:30.563 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\r\n2023-04-06 10:46:30.678 \r\n  Warning: to view this Streamlit app on a browser, run it with the following\r\n  command:\r\n\r\n    streamlit run /Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py [ARGUMENTS]\r\n2023-04-06 10:46:30.680 `st.cache` is deprecated. Please use one of Streamlit's new caching commands,\r\n`st.cache_data` or `st.cache_resource`.\r\n\r\nMore information [in our docs](https://docs.streamlit.io/library/advanced-features/caching).\r\n2023-04-06 10:46:30.681 No runtime found, using MemoryCacheStorageManager\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\r\n    reduce_data = obj.__reduce__()\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\r\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\r\nTypeError: cannot pickle 'function' object\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py\", line 20, in <module>\r\n    doesnt_work(some_id)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 194, in wrapper\r\n    return cached_func(*args, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 223, in __call__\r\n    return self._get_or_create_cached_value(args, kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 237, in _get_or_create_cached_value\r\n    value_key = _make_value_key(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 381, in _make_value_key\r\n    raise UnhashableParamError(cache_type, func, arg_name, arg_value, exc)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableParamError: Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n\r\nTo address this, you can tell Streamlit not to hash this argument by adding a\r\nleading underscore to the argument's name in the function signature:\r\n\r\n\\\\```\r\n@st.cache_data\r\ndef doesnt_work(_some_id, ...):\r\n    ...\r\n\\\\```\r\n            \r\nWorks\r\n```\r\n\r\n### Is this a regression?\r\n\r\n- [ ] Yes, this used to work in a previous version.\r\n\r\n### Debug info\r\n\r\n- Streamlit version: 1.20.0\r\n- Python version: 3.10.10\r\n- Operating System: macOS 13.2.1 (22D68)\r\n- Browser: —\r\n- Virtual environment: conda\r\n\r\n\r\n### Additional Information\r\n\r\nThe root of the problems seems to be this:\r\n```\r\nCannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n```\r\nWhich is a little strange because pickling and hashing `UUID` objects does not seem to be a problem in general:\r\n```python\r\n>>> import pickle\r\n>>> import uuid\r\n>>> pickle.dumps(uuid.uuid4())\r\nb'\\\\x80\\\\x04\\\\x950\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x8c\\\\x04uuid\\\\x94\\\\x8c\\\\x04UUID\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94\\\\x8c\\\\x03int\\\\x94\\\\x8a\\\\x10\\\\xa8\\\\x0eL\\\\x84\\\\x14\\\\xd9\\\\xcf\\\\x8d\\\\xae@M\\\\x9e\\\\x11\\\\xb0\\\\x9cvsb.'\r\n>>> hash(uuid.uuid4())\r\n1532964488252874118\r\n```\r\n\r\nA simple workaround for now is to cast `UUID` objects to strings (which are cacheable also with `@st.cache_data`), but of course it would be nicer if that were not necessary :)\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] Yes, I am willing to submit a PR!\n</bug_description>\n\nThe repository name is:\n<repo_name>\nstreamlit/streamlit\n</repo_name>\n\nYou have access to the following tools:\n\n* extract_relevant() -> Retrieve the most relevant info from the bug. Returns a JSON object with explanation, relevant code snippets, error messages and file paths mentioned in the bug. *\n\nYou must use these tools to find 10 files that are most likely to contain the bug. Start by analyzing the issue description and then decide which tool to use first.\nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}, {"role": "assistant", "content": "extracted info: {'explanation': \"The @st.cache_data decorator fails to handle uuid.UUID objects while @st.cache works fine. The error occurs during hashing when trying to pickle UUID objects, resulting in UnhashableTypeError. The issue is in the caching mechanism's hash generation for UUID objects.\", 'path': '/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py', 'filename': 'hashing.py', 'identifiers': ['uuid.UUID', 'st.cache_data', 'st.cache'], 'code snippet': '@st.cache_data\\ndef doesnt_work(some_id: uuid.UUID) -> None:\\n    print(\"Nope\")', 'stacktrace': 'Traceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\\n    reduce_data = obj.__reduce__()\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\\nTypeError: cannot pickle \\'function\\' object\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\\n    update_hash(\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\\n    ch.update(hasher, val)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\\n    raise UnhashableTypeError() from ex\\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError', 'error_message': \"Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\"}"}, {"role": "user", "content": "\nBased on the tool call results, please select your next action. Recall that you need to provide the 10 files most likely to contain bugs.\n<tool_called>\nextract_relevant\n</tool_called>\n<args>\n{}\n</args>\n\nYou have access to the following tools: \n* get_bm25_top10() -> Retrieve the top-10 best results with BM25 search. *\n* get_bm25_top20() -> Retrieve the top-20 best results with BM25 search.*\n* get_bm25_top30() -> Retrieve the top-30 best results with BM25 search. *\n \nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}, {"role": "assistant", "content": "bm25 results: {\"files\": ['lib/streamlit/runtime/legacy_caching/hashing.py', 'lib/streamlit/runtime/caching/cache_utils.py', 'lib/streamlit/runtime/legacy_caching/caching.py', 'lib/streamlit/runtime/caching/cache_data_api.py', 'lib/streamlit/runtime/caching/cache_errors.py', 'lib/streamlit/runtime/caching/hashing.py', 'lib/streamlit/runtime/caching/cached_message_replay.py', 'lib/streamlit/web/cli.py', 'lib/streamlit/config.py', 'lib/streamlit/runtime/caching/cache_resource_api.py', 'lib/streamlit/runtime/caching/storage/local_disk_cache_storage.py', 'lib/streamlit/runtime/caching/storage/cache_storage_protocol.py', 'lib/streamlit/runtime/runtime.py', 'e2e/scripts/st_markdown_in_alert_box.py', 'lib/streamlit/runtime/metrics_util.py', 'e2e/scripts/st_exception.py', 'lib/streamlit/runtime/scriptrunner/script_runner.py', 'lib/streamlit/runtime/app_session.py', 'lib/streamlit/elements/arrow.py', 'lib/streamlit/components/v1/components.py'], \"scores\": [43.35219955444336, 38.41400146484375, 37.943199157714844, 35.43239974975586, 31.0044002532959, 30.568899154663086, 28.694299697875977, 27.960399627685547, 27.353500366210938, 27.302799224853516, 26.719499588012695, 26.419099807739258, 25.60700035095215, 24.86639976501465, 24.01490020751953, 23.94420051574707, 23.680099487304688, 23.027299880981445, 19.934099197387695, 19.298999786376953]}"}, {"role": "user", "content": "\nBased on the tool call results, please select your next action. Recall that you need to provide the 10 files most likely to contain bugs.\n\n<tool_called>\nget_bm25_top20\n</tool_called>\n<args>\n{'query': 'streamlit cache_data uuid hashing'}\n</args>\n\nYou have access to the following tools: \n* view_file(`file_path`) -> View the content of the specified file. *\n* view_readme() -> View the content of the README file in the repository. *\n\nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\n\nReply ONLY with the JSON response. Remember, do not try to complete the code.\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/caching/hashing.py: \"\"\"Hashing for st.memo and st.singleton.\"\"\"\n\n# If a dataframe has more than this many rows, we consider it large and hash a sample.\n_PANDAS_ROWS_LARGE = 100000\n_PANDAS_SAMPLE_SIZE = 10000\n\n# Similar to dataframes, we also sample large numpy arrays.\n_NP_SIZE_LARGE = 1000000\n_NP_SAMPLE_SIZE = 100000\n\n# Arbitrary item to denote where we found a cycle in a hashed object.\n# This allows us to hash self-referencing lists, dictionaries, etc.\n_CYCLE_PLACEHOLDER = b\"streamlit-57R34ML17-hesamagicalponyflyingthroughthesky-CYCLE\"\n\ndef update_hash(val: Any, hasher, cache_type: CacheType) -> None:\n    \"\"\"Updates a hashlib hasher with the hash of val.\n\n    This is the main entrypoint to hashing.py.\n    \"\"\"\n    ch = _CacheFuncHasher(cache_type)\n    ch.update(hasher, val)\n\nclass _HashStack:\n    \"\"\"Stack of what has been hashed, for debug and circular reference detection.\n\n    This internally keeps 1 stack per thread.\n\n    Internally, this stores the ID of pushed objects rather than the objects\n    themselves because otherwise the \"in\" operator inside __contains__ would\n    fail for objects that don't return a boolean for \"==\" operator. For\n    example, arr == 10 where arr is a NumPy array returns another NumPy array.\n    This causes the \"in\" to crash since it expects a boolean.\n    \"\"\"\n\n    def __init__(self):\n        self._stack: collections.OrderedDict[int, List[Any]] = collections.OrderedDict()\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def push(self, val: Any):\n        self._stack[id(val)] = val\n\n    def pop(self):\n        self._stack.popitem()\n\n    def __contains__(self, val: Any):\n        return id(val) in self._stack\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/caching/cache_utils.py: \"\"\"Common cache logic shared by st.cache_data and st.cache_resource.\"\"\"\n\nfrom streamlit.runtime.caching.cache_errors import (\n    CacheError,\n    CacheKeyNotFoundError,\n    UnevaluatedDataFrameError,\n    UnhashableParamError,\n    UnhashableTypeError,\n    UnserializableReturnValueError,\n    get_cached_func_name_md,\n)\nfrom streamlit.runtime.caching.cached_message_replay import (\n    CachedMessageReplayContext,\n    CachedResult,\n    MsgData,\n    replay_cached_messages,\n)\n\n_LOGGER = get_logger(__name__)\n\n# The timer function we use with TTLCache. This is the default timer func, but\n# is exposed here as a constant so that it can be patched in unit tests.\nTTLCACHE_TIMER = time.monotonic\n\n@overload\ndef ttl_to_seconds(\n    ttl: float | timedelta | None, *, coerce_none_to_inf: Literal[False]\n) -> float | None:\n    ...\n\n@overload\ndef ttl_to_seconds(ttl: float | timedelta | None) -> float:\n    ...\n\ndef ttl_to_seconds(\n    ttl: float | timedelta | None, *, coerce_none_to_inf: bool = True\n) -> float | None:\n    \"\"\"\n    Convert a ttl value to a float representing \"number of seconds\".\n    \"\"\"\n    if coerce_none_to_inf and ttl is None:\n        return math.inf\n    if isinstance(ttl, timedelta):\n        return ttl.total_seconds()\n    return ttl\n\n# We show a special \"UnevaluatedDataFrame\" warning for cached funcs\n# that attempt to return one of these unserializable types:\nUNEVALUATED_DATAFRAME_TYPES = (\n    \"snowflake.snowpark.table.Table\",\n    \"snowflake.snowpark.dataframe.DataFrame\",\n    \"pyspark.sql.dataframe.DataFrame\",\n)\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/legacy_caching/hashing.py: \"\"\"A hashing utility for code.\"\"\"\n\n# If a dataframe has more than this many rows, we consider it large and hash a sample.\n_PANDAS_ROWS_LARGE = 100000\n_PANDAS_SAMPLE_SIZE = 10000\n\n# Similar to dataframes, we also sample large numpy arrays.\n_NP_SIZE_LARGE = 1000000\n_NP_SAMPLE_SIZE = 100000\n\n# Arbitrary item to denote where we found a cycle in a hashed object.\n# This allows us to hash self-referencing lists, dictionaries, etc.\n_CYCLE_PLACEHOLDER = b\"streamlit-57R34ML17-hesamagicalponyflyingthroughthesky-CYCLE\"\n\n# This needs to be initialized lazily to avoid calling config.get_option() and\n# thus initializing config options when this file is first imported.\n_FOLDER_BLACK_LIST = None\n\n# FFI objects (objects that interface with C libraries) can be any of these types:\n_FFI_TYPE_NAMES = [\n    \"_cffi_backend.FFI\",\n    \"builtins.CompiledFFI\",\n]\n\n# KERAS objects can be any of these types:\n_KERAS_TYPE_NAMES = [\n    \"keras.engine.training.Model\",\n    \"tensorflow.python.keras.engine.training.Model\",\n    \"tensorflow.python.keras.engine.functional.Functional\",\n]\n\nContext = collections.namedtuple(\"Context\", [\"globals\", \"cells\", \"varnames\"])\n\n# Mapping of types or fully qualified names to hash functions. This is used to\n# override the behavior of the hasher inside Streamlit's caching mechanism:\n# when the hasher encounters an object, it will first check to see if its type\n# matches a key in this dict and, if so, will use the provided function to\n# generate a hash for it.\nHashFuncsDict = Dict[Union[str, Type[Any]], Callable[[Any], Any]]\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/caching/cache_data_api.py: \"\"\"@st.cache_data: pickle-based caching\"\"\"\n\nfrom streamlit.runtime.caching.cache_utils import (\n    Cache,\n    CachedFuncInfo,\n    make_cached_func_wrapper,\n    ttl_to_seconds,\n)\nfrom streamlit.runtime.caching.cached_message_replay import (\n    CachedMessageReplayContext,\n    CachedResult,\n    ElementMsgData,\n    MsgData,\n    MultiCacheResults,\n)\nfrom streamlit.runtime.caching.storage import (\n    CacheStorage,\n    CacheStorageContext,\n    CacheStorageError,\n    CacheStorageKeyNotFoundError,\n    CacheStorageManager,\n)\nfrom streamlit.runtime.caching.storage.cache_storage_protocol import (\n    InvalidCacheStorageContext,\n)\nfrom streamlit.runtime.caching.storage.dummy_cache_storage import (\n    MemoryCacheStorageManager,\n)\n\n_LOGGER = get_logger(__name__)\n\nCACHE_DATA_MESSAGE_REPLAY_CTX = CachedMessageReplayContext(CacheType.DATA)\n\n# The cache persistence options we support: \"disk\" or None\nCachePersistType: TypeAlias = Union[Literal[\"disk\"], None]\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}], "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:19.714141+00:00"}
{"type": "response", "step": "turn_3", "response": "{\"function_call\":\"view_file\",\"args\":{\"file_path\":\"lib/streamlit/runtime/caching/cache_errors.py\"}}", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:21.854676+00:00"}
{"type": "parse", "step": "turn_3", "method": "json", "ok": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:21.859814+00:00"}
{"type": "parse", "step": "turn_3", "parsed": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:21.859918+00:00"}
{"type": "tool_decision", "step": "turn_3_tool", "tool_name": "view_file", "tool_args": {"file_path": "lib/streamlit/runtime/caching/cache_errors.py"}, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:21.859981+00:00"}
{"type": "preview_filter", "step": "turn_3_tool", "file": "lib/streamlit/runtime/caching/cache_errors.py", "removed_lines": 29, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:21.861840+00:00"}
{"type": "tool_result", "step": "turn_3_tool", "view_file": "lib/streamlit/runtime/caching/cache_errors.py", "content": "from streamlit.errors import (\n    MarkdownFormattedException,\n    StreamlitAPIException,\n    StreamlitAPIWarning,\n)\n\nCACHE_DOCS_URL = \"https://docs.streamlit.io/library/advanced-features/caching\"\n\ndef get_cached_func_name_md(func: Any) -> str:\n    \"\"\"Get markdown representation of the function name.\"\"\"\n    if hasattr(func, \"__name__\"):\n        return \"`%s()`\" % func.__name__\n    elif hasattr(type(func), \"__name__\"):\n        return f\"`{type(func).__name__}`\"\n    return f\"`{type(func)}`\"\n\ndef get_return_value_type(return_value: Any) -> str:\n    if hasattr(return_value, \"__module__\") and hasattr(type(return_value), \"__name__\"):\n        return f\"`{return_value.__module__}.{type(return_value).__name__}`\"\n    return get_cached_func_name_md(return_value)\n\nclass UnhashableTypeError(Exception):\n    pass\n\nclass UnhashableParamError(StreamlitAPIException):\n    def __init__(\n        self,\n        cache_type: CacheType,\n        func: types.FunctionType,\n        arg_name: Optional[str],\n        arg_value: Any,\n        orig_exc: BaseException,\n    ):\n        msg = self._create_message(cache_type, func, arg_name, arg_value)\n        super().__init__(msg)\n        self.with_traceback(orig_exc.__traceback__)\n\n    @staticmethod\n    def _create_message(\n        cache_type: CacheType,\n        func: types.FunctionType,\n        arg_name: Optional[str],\n        arg_value: Any,\n    ) -> str:\n        arg_name_str = arg_name if arg_name is not None else \"(unnamed)\"\n        arg_type = type_util.get_fqn_type(arg_value)\n        func_name = func.__name__\n        arg_replacement_name = f\"_{arg_name}\" if arg_name is not None else \"_arg\"\n\n        return (\n            f\"\"\"\nCannot hash argument '{arg_name_str}' (of type `{arg_type}`) in '{func_name}'.\n\nTo address this, you can tell Streamlit not to hash this argument by adding a\nleading underscore to the argument's name in the function signature:\n\n```\n@st.{get_decorator_api_name(cache_type)}\ndef {func_name}({arg_replacement_name}, ...):\n    ...\n```\n            \"\"\"\n        ).strip(\"\\n\")\n\nclass CacheKeyNotFoundError(Exception):\n    pass\n\nclass CacheError(Exception):\n    pass\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ...", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:21.869290+00:00"}
{"type": "token_count", "step": "turn_3", "token_count": 7562, "context_size": 16384, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:22.153688+00:00"}
{"type": "prompt", "step": "turn_3", "messages": [{"role": "system", "content": "\nYou are an expert software engineer specialized in bug localization. \nYour task is to identify the files most likely to contain bugs based on bug descriptions. \nYou have access to several tools to help you in this task. \nFrom the files you have seen, you will select 10 files that you believe are most likely to contain the bug.\n"}, {"role": "user", "content": "\n<bug_description>\n`@st.cache_data` cannot handle UUID objects (but `@st.cache` can) ### Checklist\r\n\r\n- [X] I have searched the [existing issues](https://github.com/streamlit/streamlit/issues) for similar issues.\r\n- [X] I added a very descriptive title to this issue.\r\n- [X] I have provided sufficient information below to help reproduce this issue.\r\n\r\n### Summary\r\n\r\nIt looks like the \"new\" `@st.cache_data` decorator chokes on `uuid.UUID` objects, while the deprecated `@st.cache` seems to handle them just fine; see minimal example.\r\n\r\n\r\n### Reproducible Code Example\r\n\r\n```Python\r\nimport streamlit as st\r\nimport uuid\r\n\r\n\r\n@st.cache\r\ndef works(some_id: uuid.UUID) -> None:\r\n    print(\"Works\")\r\n\r\n\r\n@st.cache_data\r\ndef doesnt_work(some_id: uuid.UUID) -> None:\r\n    print(\"Nope\")\r\n\r\n\r\nsome_id = uuid.uuid4()\r\n\r\nworks(some_id)\r\ndoesnt_work(some_id)\r\n```\r\n\r\n\r\n### Steps To Reproduce\r\n\r\n_No response_\r\n\r\n### Expected Behavior\r\n\r\n_No response_\r\n\r\n### Current Behavior\r\n\r\nThe minimal example above produces the following output:\r\n\r\n```\r\n2023-04-06 10:46:30.563 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\r\n2023-04-06 10:46:30.678 \r\n  Warning: to view this Streamlit app on a browser, run it with the following\r\n  command:\r\n\r\n    streamlit run /Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py [ARGUMENTS]\r\n2023-04-06 10:46:30.680 `st.cache` is deprecated. Please use one of Streamlit's new caching commands,\r\n`st.cache_data` or `st.cache_resource`.\r\n\r\nMore information [in our docs](https://docs.streamlit.io/library/advanced-features/caching).\r\n2023-04-06 10:46:30.681 No runtime found, using MemoryCacheStorageManager\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\r\n    reduce_data = obj.__reduce__()\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\r\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\r\nTypeError: cannot pickle 'function' object\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py\", line 20, in <module>\r\n    doesnt_work(some_id)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 194, in wrapper\r\n    return cached_func(*args, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 223, in __call__\r\n    return self._get_or_create_cached_value(args, kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 237, in _get_or_create_cached_value\r\n    value_key = _make_value_key(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 381, in _make_value_key\r\n    raise UnhashableParamError(cache_type, func, arg_name, arg_value, exc)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableParamError: Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n\r\nTo address this, you can tell Streamlit not to hash this argument by adding a\r\nleading underscore to the argument's name in the function signature:\r\n\r\n\\\\```\r\n@st.cache_data\r\ndef doesnt_work(_some_id, ...):\r\n    ...\r\n\\\\```\r\n            \r\nWorks\r\n```\r\n\r\n### Is this a regression?\r\n\r\n- [ ] Yes, this used to work in a previous version.\r\n\r\n### Debug info\r\n\r\n- Streamlit version: 1.20.0\r\n- Python version: 3.10.10\r\n- Operating System: macOS 13.2.1 (22D68)\r\n- Browser: —\r\n- Virtual environment: conda\r\n\r\n\r\n### Additional Information\r\n\r\nThe root of the problems seems to be this:\r\n```\r\nCannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n```\r\nWhich is a little strange because pickling and hashing `UUID` objects does not seem to be a problem in general:\r\n```python\r\n>>> import pickle\r\n>>> import uuid\r\n>>> pickle.dumps(uuid.uuid4())\r\nb'\\\\x80\\\\x04\\\\x950\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x8c\\\\x04uuid\\\\x94\\\\x8c\\\\x04UUID\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94\\\\x8c\\\\x03int\\\\x94\\\\x8a\\\\x10\\\\xa8\\\\x0eL\\\\x84\\\\x14\\\\xd9\\\\xcf\\\\x8d\\\\xae@M\\\\x9e\\\\x11\\\\xb0\\\\x9cvsb.'\r\n>>> hash(uuid.uuid4())\r\n1532964488252874118\r\n```\r\n\r\nA simple workaround for now is to cast `UUID` objects to strings (which are cacheable also with `@st.cache_data`), but of course it would be nicer if that were not necessary :)\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] Yes, I am willing to submit a PR!\n</bug_description>\n\nThe repository name is:\n<repo_name>\nstreamlit/streamlit\n</repo_name>\n\nYou have access to the following tools:\n\n* extract_relevant() -> Retrieve the most relevant info from the bug. Returns a JSON object with explanation, relevant code snippets, error messages and file paths mentioned in the bug. *\n\nYou must use these tools to find 10 files that are most likely to contain the bug. Start by analyzing the issue description and then decide which tool to use first.\nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}, {"role": "assistant", "content": "extracted info: {'explanation': \"The @st.cache_data decorator fails to handle uuid.UUID objects while @st.cache works fine. The error occurs during hashing when trying to pickle UUID objects, resulting in UnhashableTypeError. The issue is in the caching mechanism's hash generation for UUID objects.\", 'path': '/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py', 'filename': 'hashing.py', 'identifiers': ['uuid.UUID', 'st.cache_data', 'st.cache'], 'code snippet': '@st.cache_data\\ndef doesnt_work(some_id: uuid.UUID) -> None:\\n    print(\"Nope\")', 'stacktrace': 'Traceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\\n    reduce_data = obj.__reduce__()\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\\nTypeError: cannot pickle \\'function\\' object\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\\n    update_hash(\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\\n    ch.update(hasher, val)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\\n    self.update(h, item)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\\n    b = self.to_bytes(obj)\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\\n    raise UnhashableTypeError() from ex\\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError', 'error_message': \"Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\"}"}, {"role": "user", "content": "\nBased on the tool call results, please select your next action. Recall that you need to provide the 10 files most likely to contain bugs.\n<tool_called>\nextract_relevant\n</tool_called>\n<args>\n{}\n</args>\n\nYou have access to the following tools: \n* get_bm25_top10() -> Retrieve the top-10 best results with BM25 search. *\n* get_bm25_top20() -> Retrieve the top-20 best results with BM25 search.*\n* get_bm25_top30() -> Retrieve the top-30 best results with BM25 search. *\n \nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\nReply ONLY with the JSON response.\n\n"}, {"role": "assistant", "content": "bm25 results: {\"files\": ['lib/streamlit/runtime/legacy_caching/hashing.py', 'lib/streamlit/runtime/caching/cache_utils.py', 'lib/streamlit/runtime/legacy_caching/caching.py', 'lib/streamlit/runtime/caching/cache_data_api.py', 'lib/streamlit/runtime/caching/cache_errors.py', 'lib/streamlit/runtime/caching/hashing.py', 'lib/streamlit/runtime/caching/cached_message_replay.py', 'lib/streamlit/web/cli.py', 'lib/streamlit/config.py', 'lib/streamlit/runtime/caching/cache_resource_api.py', 'lib/streamlit/runtime/caching/storage/local_disk_cache_storage.py', 'lib/streamlit/runtime/caching/storage/cache_storage_protocol.py', 'lib/streamlit/runtime/runtime.py', 'e2e/scripts/st_markdown_in_alert_box.py', 'lib/streamlit/runtime/metrics_util.py', 'e2e/scripts/st_exception.py', 'lib/streamlit/runtime/scriptrunner/script_runner.py', 'lib/streamlit/runtime/app_session.py', 'lib/streamlit/elements/arrow.py', 'lib/streamlit/components/v1/components.py'], \"scores\": [43.35219955444336, 38.41400146484375, 37.943199157714844, 35.43239974975586, 31.0044002532959, 30.568899154663086, 28.694299697875977, 27.960399627685547, 27.353500366210938, 27.302799224853516, 26.719499588012695, 26.419099807739258, 25.60700035095215, 24.86639976501465, 24.01490020751953, 23.94420051574707, 23.680099487304688, 23.027299880981445, 19.934099197387695, 19.298999786376953]}"}, {"role": "user", "content": "\nBased on the tool call results, please select your next action. Recall that you need to provide the 10 files most likely to contain bugs.\n\n<tool_called>\nget_bm25_top20\n</tool_called>\n<args>\n{'query': 'streamlit cache_data uuid hashing'}\n</args>\n\nYou have access to the following tools: \n* view_file(`file_path`) -> View the content of the specified file. *\n* view_readme() -> View the content of the README file in the repository. *\n\nIf you are done, provide your final ranked list of 10 files most likely to contain bugs in a JSON array as follows: {\"ranked_files\": [\"file1\", \"file2\", ...]}\nOtherwise, return only the tool call as JSON. Example: {\"function_call\": \"func_name\", \"args\": {\"arg_name\": 10} }\n\nReply ONLY with the JSON response. Remember, do not try to complete the code.\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/caching/hashing.py: \"\"\"Hashing for st.memo and st.singleton.\"\"\"\n\n# If a dataframe has more than this many rows, we consider it large and hash a sample.\n_PANDAS_ROWS_LARGE = 100000\n_PANDAS_SAMPLE_SIZE = 10000\n\n# Similar to dataframes, we also sample large numpy arrays.\n_NP_SIZE_LARGE = 1000000\n_NP_SAMPLE_SIZE = 100000\n\n# Arbitrary item to denote where we found a cycle in a hashed object.\n# This allows us to hash self-referencing lists, dictionaries, etc.\n_CYCLE_PLACEHOLDER = b\"streamlit-57R34ML17-hesamagicalponyflyingthroughthesky-CYCLE\"\n\ndef update_hash(val: Any, hasher, cache_type: CacheType) -> None:\n    \"\"\"Updates a hashlib hasher with the hash of val.\n\n    This is the main entrypoint to hashing.py.\n    \"\"\"\n    ch = _CacheFuncHasher(cache_type)\n    ch.update(hasher, val)\n\nclass _HashStack:\n    \"\"\"Stack of what has been hashed, for debug and circular reference detection.\n\n    This internally keeps 1 stack per thread.\n\n    Internally, this stores the ID of pushed objects rather than the objects\n    themselves because otherwise the \"in\" operator inside __contains__ would\n    fail for objects that don't return a boolean for \"==\" operator. For\n    example, arr == 10 where arr is a NumPy array returns another NumPy array.\n    This causes the \"in\" to crash since it expects a boolean.\n    \"\"\"\n\n    def __init__(self):\n        self._stack: collections.OrderedDict[int, List[Any]] = collections.OrderedDict()\n\n    def __repr__(self) -> str:\n        return util.repr_(self)\n\n    def push(self, val: Any):\n        self._stack[id(val)] = val\n\n    def pop(self):\n        self._stack.popitem()\n\n    def __contains__(self, val: Any):\n        return id(val) in self._stack\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/caching/cache_utils.py: \"\"\"Common cache logic shared by st.cache_data and st.cache_resource.\"\"\"\n\nfrom streamlit.runtime.caching.cache_errors import (\n    CacheError,\n    CacheKeyNotFoundError,\n    UnevaluatedDataFrameError,\n    UnhashableParamError,\n    UnhashableTypeError,\n    UnserializableReturnValueError,\n    get_cached_func_name_md,\n)\nfrom streamlit.runtime.caching.cached_message_replay import (\n    CachedMessageReplayContext,\n    CachedResult,\n    MsgData,\n    replay_cached_messages,\n)\n\n_LOGGER = get_logger(__name__)\n\n# The timer function we use with TTLCache. This is the default timer func, but\n# is exposed here as a constant so that it can be patched in unit tests.\nTTLCACHE_TIMER = time.monotonic\n\n@overload\ndef ttl_to_seconds(\n    ttl: float | timedelta | None, *, coerce_none_to_inf: Literal[False]\n) -> float | None:\n    ...\n\n@overload\ndef ttl_to_seconds(ttl: float | timedelta | None) -> float:\n    ...\n\ndef ttl_to_seconds(\n    ttl: float | timedelta | None, *, coerce_none_to_inf: bool = True\n) -> float | None:\n    \"\"\"\n    Convert a ttl value to a float representing \"number of seconds\".\n    \"\"\"\n    if coerce_none_to_inf and ttl is None:\n        return math.inf\n    if isinstance(ttl, timedelta):\n        return ttl.total_seconds()\n    return ttl\n\n# We show a special \"UnevaluatedDataFrame\" warning for cached funcs\n# that attempt to return one of these unserializable types:\nUNEVALUATED_DATAFRAME_TYPES = (\n    \"snowflake.snowpark.table.Table\",\n    \"snowflake.snowpark.dataframe.DataFrame\",\n    \"pyspark.sql.dataframe.DataFrame\",\n)\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/legacy_caching/hashing.py: \"\"\"A hashing utility for code.\"\"\"\n\n# If a dataframe has more than this many rows, we consider it large and hash a sample.\n_PANDAS_ROWS_LARGE = 100000\n_PANDAS_SAMPLE_SIZE = 10000\n\n# Similar to dataframes, we also sample large numpy arrays.\n_NP_SIZE_LARGE = 1000000\n_NP_SAMPLE_SIZE = 100000\n\n# Arbitrary item to denote where we found a cycle in a hashed object.\n# This allows us to hash self-referencing lists, dictionaries, etc.\n_CYCLE_PLACEHOLDER = b\"streamlit-57R34ML17-hesamagicalponyflyingthroughthesky-CYCLE\"\n\n# This needs to be initialized lazily to avoid calling config.get_option() and\n# thus initializing config options when this file is first imported.\n_FOLDER_BLACK_LIST = None\n\n# FFI objects (objects that interface with C libraries) can be any of these types:\n_FFI_TYPE_NAMES = [\n    \"_cffi_backend.FFI\",\n    \"builtins.CompiledFFI\",\n]\n\n# KERAS objects can be any of these types:\n_KERAS_TYPE_NAMES = [\n    \"keras.engine.training.Model\",\n    \"tensorflow.python.keras.engine.training.Model\",\n    \"tensorflow.python.keras.engine.functional.Functional\",\n]\n\nContext = collections.namedtuple(\"Context\", [\"globals\", \"cells\", \"varnames\"])\n\n# Mapping of types or fully qualified names to hash functions. This is used to\n# override the behavior of the hasher inside Streamlit's caching mechanism:\n# when the hasher encounters an object, it will first check to see if its type\n# matches a key in this dict and, if so, will use the provided function to\n# generate a hash for it.\nHashFuncsDict = Dict[Union[str, Type[Any]], Callable[[Any], Any]]\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/caching/cache_data_api.py: \"\"\"@st.cache_data: pickle-based caching\"\"\"\n\nfrom streamlit.runtime.caching.cache_utils import (\n    Cache,\n    CachedFuncInfo,\n    make_cached_func_wrapper,\n    ttl_to_seconds,\n)\nfrom streamlit.runtime.caching.cached_message_replay import (\n    CachedMessageReplayContext,\n    CachedResult,\n    ElementMsgData,\n    MsgData,\n    MultiCacheResults,\n)\nfrom streamlit.runtime.caching.storage import (\n    CacheStorage,\n    CacheStorageContext,\n    CacheStorageError,\n    CacheStorageKeyNotFoundError,\n    CacheStorageManager,\n)\nfrom streamlit.runtime.caching.storage.cache_storage_protocol import (\n    InvalidCacheStorageContext,\n)\nfrom streamlit.runtime.caching.storage.dummy_cache_storage import (\n    MemoryCacheStorageManager,\n)\n\n_LOGGER = get_logger(__name__)\n\nCACHE_DATA_MESSAGE_REPLAY_CTX = CachedMessageReplayContext(CacheType.DATA)\n\n# The cache persistence options we support: \"disk\" or None\nCachePersistType: TypeAlias = Union[Literal[\"disk\"], None]\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}, {"role": "assistant", "content": "[Note: you already viewed this file. Consider choosing another file.]\nfile content: lib/streamlit/runtime/caching/cache_errors.py: from streamlit.errors import (\n    MarkdownFormattedException,\n    StreamlitAPIException,\n    StreamlitAPIWarning,\n)\n\nCACHE_DOCS_URL = \"https://docs.streamlit.io/library/advanced-features/caching\"\n\ndef get_cached_func_name_md(func: Any) -> str:\n    \"\"\"Get markdown representation of the function name.\"\"\"\n    if hasattr(func, \"__name__\"):\n        return \"`%s()`\" % func.__name__\n    elif hasattr(type(func), \"__name__\"):\n        return f\"`{type(func).__name__}`\"\n    return f\"`{type(func)}`\"\n\ndef get_return_value_type(return_value: Any) -> str:\n    if hasattr(return_value, \"__module__\") and hasattr(type(return_value), \"__name__\"):\n        return f\"`{return_value.__module__}.{type(return_value).__name__}`\"\n    return get_cached_func_name_md(return_value)\n\nclass UnhashableTypeError(Exception):\n    pass\n\nclass UnhashableParamError(StreamlitAPIException):\n    def __init__(\n        self,\n        cache_type: CacheType,\n        func: types.FunctionType,\n        arg_name: Optional[str],\n        arg_value: Any,\n        orig_exc: BaseException,\n    ):\n        msg = self._create_message(cache_type, func, arg_name, arg_value)\n        super().__init__(msg)\n        self.with_traceback(orig_exc.__traceback__)\n\n    @staticmethod\n    def _create_message(\n        cache_type: CacheType,\n        func: types.FunctionType,\n        arg_name: Optional[str],\n        arg_value: Any,\n    ) -> str:\n        arg_name_str = arg_name if arg_name is not None else \"(unnamed)\"\n        arg_type = type_util.get_fqn_type(arg_value)\n        func_name = func.__name__\n        arg_replacement_name = f\"_{arg_name}\" if arg_name is not None else \"_arg\"\n\n        return (\n            f\"\"\"\nCannot hash argument '{arg_name_str}' (of type `{arg_type}`) in '{func_name}'.\n\nTo address this, you can tell Streamlit not to hash this argument by adding a\nleading underscore to the argument's name in the function signature:\n\n```\n@st.{get_decorator_api_name(cache_type)}\ndef {func_name}({arg_replacement_name}, ...):\n    ...\n```\n            \"\"\"\n        ).strip(\"\\n\")\n\nclass CacheKeyNotFoundError(Exception):\n    pass\n\nclass CacheError(Exception):\n    pass\n\n# ... [FILE TRUNCATED - REMAINING CODE OMITTED] ..."}, {"role": "user", "content": "\nYou are analyzing code. The code may be truncated. \nDO NOT attempt to complete incomplete functions or classes. \nIf you see incomplete code, work with what's available.\n\nSelect your next action. Remember you need to provide the 10 files most likely to contain bugs.\nYou may reply with ONE of these JSON shapes ONLY:\nA) {\"ranked_files\": [\"file1\", \"file2\", ...], \"confidence_scores\": [\"score1\", \"score2\", ...]}\nB) {\"function_call\":\"view_file\",\"args\":{\"file_path\":string}}\nNever include code blocks, file contents, or extra keys.\n\nReply ONLY with the required JSON format.\n\n"}], "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:22.153885+00:00"}
{"type": "response", "step": "turn_3", "response": "{\"ranked_files\": [\"lib/streamlit/runtime/caching/hashing.py\", \"lib/streamlit/runtime/caching/cache_utils.py\", \"lib/streamlit/runtime/legacy_caching/hashing.py\", \"lib/streamlit/runtime/caching/cache_data_api.py\", \"lib/streamlit/runtime/caching/cache_errors.py\", \"lib/streamlit/runtime/caching/cache_resource_api.py\", \"lib/streamlit/runtime/caching/storage/cache_storage_protocol.py\", \"lib/streamlit/runtime/caching/storage/local_disk_cache_storage.py\", \"lib/streamlit/runtime/caching/cached_message_replay.py\", \"lib/streamlit/runtime/legacy_caching/caching.py\"]}", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:29.043394+00:00"}
{"type": "parse", "step": "turn_3", "method": "json", "ok": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:29.048848+00:00"}
{"type": "parse", "step": "turn_3", "parsed": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:29.048958+00:00"}
{"type": "final_answer", "step": "turn_3", "ranked_files": ["lib/streamlit/runtime/caching/hashing.py", "lib/streamlit/runtime/caching/cache_utils.py", "lib/streamlit/runtime/legacy_caching/hashing.py", "lib/streamlit/runtime/caching/cache_data_api.py", "lib/streamlit/runtime/caching/cache_errors.py", "lib/streamlit/runtime/caching/cache_resource_api.py", "lib/streamlit/runtime/caching/storage/cache_storage_protocol.py", "lib/streamlit/runtime/caching/storage/local_disk_cache_storage.py", "lib/streamlit/runtime/caching/cached_message_replay.py", "lib/streamlit/runtime/legacy_caching/caching.py"], "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:29.053154+00:00"}
{"type": "token_count", "step": "self_eval", "token_count": 3415, "context_size": 16384, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:29.368093+00:00"}
{"type": "prompt", "step": "self_eval", "messages": [{"role": "system", "content": "\n\nYou are an expert software engineer specialized in bug localization. \nYour task is to review a ranked list of files most likely to contain bugs based on a bug description. \nYou have access to the evidence seen during the investigation, such as file views and BM25 retrievals.\nYour goal is to review and/or adjust the ranked list of files based on your confidence that each file contains the bug.\n"}, {"role": "user", "content": "\nThis is the bug description:\n<bug_description>\n`@st.cache_data` cannot handle UUID objects (but `@st.cache` can) ### Checklist\r\n\r\n- [X] I have searched the [existing issues](https://github.com/streamlit/streamlit/issues) for similar issues.\r\n- [X] I added a very descriptive title to this issue.\r\n- [X] I have provided sufficient information below to help reproduce this issue.\r\n\r\n### Summary\r\n\r\nIt looks like the \"new\" `@st.cache_data` decorator chokes on `uuid.UUID` objects, while the deprecated `@st.cache` seems to handle them just fine; see minimal example.\r\n\r\n\r\n### Reproducible Code Example\r\n\r\n```Python\r\nimport streamlit as st\r\nimport uuid\r\n\r\n\r\n@st.cache\r\ndef works(some_id: uuid.UUID) -> None:\r\n    print(\"Works\")\r\n\r\n\r\n@st.cache_data\r\ndef doesnt_work(some_id: uuid.UUID) -> None:\r\n    print(\"Nope\")\r\n\r\n\r\nsome_id = uuid.uuid4()\r\n\r\nworks(some_id)\r\ndoesnt_work(some_id)\r\n```\r\n\r\n\r\n### Steps To Reproduce\r\n\r\n_No response_\r\n\r\n### Expected Behavior\r\n\r\n_No response_\r\n\r\n### Current Behavior\r\n\r\nThe minimal example above produces the following output:\r\n\r\n```\r\n2023-04-06 10:46:30.563 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\r\n2023-04-06 10:46:30.678 \r\n  Warning: to view this Streamlit app on a browser, run it with the following\r\n  command:\r\n\r\n    streamlit run /Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py [ARGUMENTS]\r\n2023-04-06 10:46:30.680 `st.cache` is deprecated. Please use one of Streamlit's new caching commands,\r\n`st.cache_data` or `st.cache_resource`.\r\n\r\nMore information [in our docs](https://docs.streamlit.io/library/advanced-features/caching).\r\n2023-04-06 10:46:30.681 No runtime found, using MemoryCacheStorageManager\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 383, in _to_bytes\r\n    reduce_data = obj.__reduce__()\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py\", line 76, in _reduce_ex\r\n    raise TypeError(f\"cannot pickle {cls.__name__!r} object\")\r\nTypeError: cannot pickle 'function' object\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableTypeError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py\", line 20, in <module>\r\n    doesnt_work(some_id)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 194, in wrapper\r\n    return cached_func(*args, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 223, in __call__\r\n    return self._get_or_create_cached_value(args, kwargs)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 237, in _get_or_create_cached_value\r\n    value_key = _make_value_key(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 381, in _make_value_key\r\n    raise UnhashableParamError(cache_type, func, arg_name, arg_value, exc)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py\", line 375, in _make_value_key\r\n    update_hash(\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 56, in update_hash\r\n    ch.update(hasher, val)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 239, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 388, in _to_bytes\r\n    self.update(h, item)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 209, in update\r\n    b = self.to_bytes(obj)\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 191, in to_bytes\r\n    b = b\"%s:%s\" % (tname, self._to_bytes(obj))\r\n  File \"/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py\", line 385, in _to_bytes\r\n    raise UnhashableTypeError() from ex\r\nstreamlit.runtime.caching.cache_errors.UnhashableParamError: Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n\r\nTo address this, you can tell Streamlit not to hash this argument by adding a\r\nleading underscore to the argument's name in the function signature:\r\n\r\n\\\\```\r\n@st.cache_data\r\ndef doesnt_work(_some_id, ...):\r\n    ...\r\n\\\\```\r\n            \r\nWorks\r\n```\r\n\r\n### Is this a regression?\r\n\r\n- [ ] Yes, this used to work in a previous version.\r\n\r\n### Debug info\r\n\r\n- Streamlit version: 1.20.0\r\n- Python version: 3.10.10\r\n- Operating System: macOS 13.2.1 (22D68)\r\n- Browser: —\r\n- Virtual environment: conda\r\n\r\n\r\n### Additional Information\r\n\r\nThe root of the problems seems to be this:\r\n```\r\nCannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.\r\n```\r\nWhich is a little strange because pickling and hashing `UUID` objects does not seem to be a problem in general:\r\n```python\r\n>>> import pickle\r\n>>> import uuid\r\n>>> pickle.dumps(uuid.uuid4())\r\nb'\\\\x80\\\\x04\\\\x950\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x8c\\\\x04uuid\\\\x94\\\\x8c\\\\x04UUID\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94\\\\x8c\\\\x03int\\\\x94\\\\x8a\\\\x10\\\\xa8\\\\x0eL\\\\x84\\\\x14\\\\xd9\\\\xcf\\\\x8d\\\\xae@M\\\\x9e\\\\x11\\\\xb0\\\\x9cvsb.'\r\n>>> hash(uuid.uuid4())\r\n1532964488252874118\r\n```\r\n\r\nA simple workaround for now is to cast `UUID` objects to strings (which are cacheable also with `@st.cache_data`), but of course it would be nicer if that were not necessary :)\r\n\r\n### Are you willing to submit a PR?\r\n\r\n- [ ] Yes, I am willing to submit a PR!\n</bug_description>\n\nBM25 retrieved the following files:\n<bm25_retrieved>\n{\n  \"files\": [\n    \"lib/streamlit/runtime/legacy_caching/hashing.py\",\n    \"lib/streamlit/runtime/caching/cache_utils.py\",\n    \"lib/streamlit/runtime/legacy_caching/caching.py\",\n    \"lib/streamlit/runtime/caching/cache_data_api.py\",\n    \"lib/streamlit/runtime/caching/cache_errors.py\",\n    \"lib/streamlit/runtime/caching/hashing.py\",\n    \"lib/streamlit/runtime/caching/cached_message_replay.py\",\n    \"lib/streamlit/web/cli.py\",\n    \"lib/streamlit/config.py\",\n    \"lib/streamlit/runtime/caching/cache_resource_api.py\",\n    \"lib/streamlit/runtime/caching/storage/local_disk_cache_storage.py\",\n    \"lib/streamlit/runtime/caching/storage/cache_storage_protocol.py\",\n    \"lib/streamlit/runtime/runtime.py\",\n    \"e2e/scripts/st_markdown_in_alert_box.py\",\n    \"lib/streamlit/runtime/metrics_util.py\",\n    \"e2e/scripts/st_exception.py\",\n    \"lib/streamlit/runtime/scriptrunner/script_runner.py\",\n    \"lib/streamlit/runtime/app_session.py\",\n    \"lib/streamlit/elements/arrow.py\",\n    \"lib/streamlit/components/v1/components.py\"\n  ]\n}\n</bm25_retrieved>\n\nYou have also viewed the following files during your investigation:\n<viewed_files>\n[\"lib/streamlit/runtime/caching/hashing.py\", \"lib/streamlit/runtime/caching/cache_utils.py\", \"lib/strea... <truncated 2007 chars>"}], "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:29.368292+00:00"}
{"type": "response", "step": "self_eval", "response": "{\n    \"ranked_files\": [\n        \"lib/streamlit/runtime/caching/hashing.py\",\n        \"lib/streamlit/runtime/caching/cache_utils.py\",\n        \"lib/streamlit/runtime/legacy_caching/hashing.py\",\n        \"lib/streamlit/runtime/caching/cache_data_api.py\",\n        \"lib/streamlit/runtime/caching/cache_errors.py\",\n        \"lib/streamlit/runtime/caching/cache_resource_api.py\",\n        \"lib/streamlit/runtime/caching/storage/cache_storage_protocol.py\",\n        \"lib/streamlit/runtime/caching/storage/local_disk_cache_storage.py\",\n        \"lib/streamlit/runtime/caching/cached_message_replay.py\",\n        \"lib/streamlit/runtime/legacy_caching/caching.py\"\n    ],\n    \"confidence_scores\": [\n        \"9\",\n        \"8\",\n        \"7\",\n        \"7\",\n        \"6\",\n        \"5\",\n        \"4\",\n        \"4\",\n        \"3\",\n        \"3\"\n    ]\n}", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:38.308901+00:00"}
{"type": "parse", "step": "self_eval", "method": "json", "ok": true, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:38.314305+00:00"}
{"type": "self_eval_applied", "step": "self_eval", "ranked_files": ["lib/streamlit/runtime/caching/hashing.py", "lib/streamlit/runtime/caching/cache_utils.py", "lib/streamlit/runtime/legacy_caching/hashing.py", "lib/streamlit/runtime/caching/cache_data_api.py", "lib/streamlit/runtime/caching/cache_errors.py", "lib/streamlit/runtime/caching/cache_resource_api.py", "lib/streamlit/runtime/caching/storage/cache_storage_protocol.py", "lib/streamlit/runtime/caching/storage/local_disk_cache_storage.py", "lib/streamlit/runtime/caching/cached_message_replay.py", "lib/streamlit/runtime/legacy_caching/caching.py"], "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:38.315279+00:00"}
{"type": "end", "step": "pipeline", "ranked_files": ["lib/streamlit/runtime/caching/hashing.py", "lib/streamlit/runtime/caching/cache_utils.py", "lib/streamlit/runtime/legacy_caching/hashing.py", "lib/streamlit/runtime/caching/cache_data_api.py", "lib/streamlit/runtime/caching/cache_errors.py", "lib/streamlit/runtime/caching/cache_resource_api.py", "lib/streamlit/runtime/caching/storage/cache_storage_protocol.py", "lib/streamlit/runtime/caching/storage/local_disk_cache_storage.py", "lib/streamlit/runtime/caching/cached_message_replay.py", "lib/streamlit/runtime/legacy_caching/caching.py"], "reprompts": 0, "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "ts": "2025-09-30T00:49:38.315409+00:00"}
{"type": "summary", "run_id": "streamlit__streamlit__76bba47f71eeeca22c52d4e599387bb416da15ca_9", "model": "qwen3-coder-16k", "reprompts": 0, "events": 66, "started_at": "2025-09-30T00:49:01.127590+00:00", "finished_at": "2025-09-30T00:49:38.316983+00:00", "ts": "2025-09-30T00:49:38.316990+00:00"}
